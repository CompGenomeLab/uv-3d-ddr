{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioframe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gseapy as gp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import glob\n",
    "import cooler\n",
    "#bm = gp.Biomart()\n",
    "\n",
    "pd.options.mode.chained_assignment = None # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions and files ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read gtf\n",
    "gtf = \"/home/carlos/oldies/manuscripts/notebooks/unibind/GRCh38.gtf\"\n",
    "genes_all = bioframe.read_table(gtf, schema='gtf').query('feature==\"CDS\"')\n",
    "genes_all.start = genes_all.start.astype(int)\n",
    "genes_all.end = genes_all.end.astype(int)\n",
    "genes_all.sort_values(by=['chrom', 'start'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use appris or mane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/carlos/oldies/manuscripts/notebooks/RNA/appris_data.appris.txt\", sep='\\t')\n",
    "df = df.loc[df[\"MANE\"].isin(['MANE_Select'])] #, 'MANE_Plus_Clinical'])]\n",
    "mane_tx_list = df['Transcript ID'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = genes_all.copy()\n",
    "genes['gene_id'] = [gene_id.split(\".\")[0] for gene_id in genes.attributes.str.extract(r'gene_id \"(.*?)\";', expand=False)]\n",
    "genes['tx_id'] = [tx_id.split(\".\")[0] for tx_id in genes.attributes.str.extract(r'transcript_id \"(.*?)\";', expand=False)]\n",
    "genes['external_gene_name'] = [gene_name.split(\".\")[0] for gene_name in genes.attributes.str.extract(r'gene_name \"(.*?)\";', expand=False)]\n",
    "genes = genes.loc[genes['tx_id'].isin(mane_tx_list)]\n",
    "genes.sort_values(by=['chrom', 'start'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_adjusted = []\n",
    "for tx_id, tx_df in genes.groupby('tx_id').__iter__():\n",
    "    if \"+\" in tx_df.strand.to_list():\n",
    "        tx_adjusted.append(tx_df.iloc[0, :])\n",
    "    elif \"-\" in tx_df.strand.to_list():\n",
    "        tx_adjusted.append(tx_df.iloc[-1, :])\n",
    "\n",
    "genes = pd.concat(tx_adjusted, axis=1).T\n",
    "genes.reset_index(drop=True, inplace=True)\n",
    "genes.start = genes.start.astype(int)\n",
    "genes.end = genes.end.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "human = pd.Series(gp.get_library_name(organism='Human'))\n",
    "pathways = human.loc[human.str.contains(\"MSigDB_Hallmark_2020\") | human.str.contains(\"GO_Biological_Process_2023\") | human.str.contains(\"NCI-Nature_2016\")].reset_index(drop=True)\n",
    "#pathways = human.loc[human.str.contains(\"MSigDB_Hallmark_2020\") | human.str.contains(\"NCI-Nature_2016\") ].reset_index(drop=True)\n",
    "pathways = {\n",
    "    pathway: gp.get_library(name=pathway, organism='Human')\n",
    "    for pathway in pathways\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrichrrr(\n",
    "    degs_list: list, \n",
    "    pathways_dict: dict, \n",
    "    universe_list: list = None):\n",
    "    results = []\n",
    "\n",
    "    for pathway_name, gene_sets in pathways_dict.items():\n",
    "        enr = gp.enrichr(gene_list=degs_list,\n",
    "                     gene_sets=gene_sets,\n",
    "                     #gene_sets = pathway_name,\n",
    "                     outdir=None,\n",
    "                     background=universe_list,\n",
    "                     verbose=False)\n",
    "        results.append(enr)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlapper(\n",
    "    current_degs_df: pd.DataFrame, \n",
    "    my_regions_df: pd.DataFrame, \n",
    "    all_genes: pd.DataFrame, \n",
    "    tss_coord_only: bool = True, # True if you want to use only the TSS coordinates (point-wise), False if you want to create a window around the TSS\n",
    "    upstream: int =2000, \n",
    "    downstream: int =500,\n",
    "    returnNames = True):\n",
    "    strand_oriented_genes = all_genes.copy()\n",
    "\n",
    "    if tss_coord_only == True:\n",
    "        strand_oriented_genes['start'] = all_genes.apply(lambda x: x['start'] if x['strand'] == \"+\" else x['end'], axis=1)\n",
    "        strand_oriented_genes['end'] = strand_oriented_genes['start']\n",
    "    else:\n",
    "        strand_oriented_genes['start'] = all_genes.apply(lambda x: x['start'] - upstream if x['strand'] == 1 else x['end'] - downstream, axis=1)\n",
    "        strand_oriented_genes['end'] = all_genes.apply(lambda x: x['start'] + downstream if x['strand'] == 1 else x['end'] + upstream, axis=1)\n",
    "\n",
    "    my_regions_universe = bioframe.overlap(strand_oriented_genes, my_regions_df, how='inner')\n",
    "    degs_filter = current_degs_df.loc[current_degs_df['ensembl_gene_id'].isin(my_regions_universe['gene_id'])]\n",
    "    \n",
    "    if returnNames == True:\n",
    "        return list(degs_filter.external_gene_name.dropna().unique()), my_regions_universe\n",
    "    else:\n",
    "        return degs_filter, my_regions_universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_enrs_into_common_df(res_1, res_2):\n",
    "    comparison_dfs = []\n",
    "\n",
    "    for i, (enr1, enr2) in enumerate(zip(res_1, res_2)):\n",
    "        df1 = enr1.results.sort_values('Adjusted P-value')\n",
    "        df2 = enr2.results.sort_values('Adjusted P-value')\n",
    "        sig_terms_df1 = df1.loc[df1['Adjusted P-value'] <= 0.05].Term\n",
    "        sig_terms_df2 = df2.loc[df2['Adjusted P-value'] <= 0.05].Term\n",
    "        df1['logPadj'] = -np.log10(df1['Adjusted P-value'])\n",
    "        df2['logPadj'] = -np.log10(df2['Adjusted P-value'])\n",
    "        \n",
    "        # merge dfs\n",
    "        df = pd.merge(df1, df2, on='Term', suffixes=('_0_12', '_0_60'))\n",
    "        if i == 2:\n",
    "            df = df.loc[df['logPadj_0_60'] >= 1.3]\n",
    "        # keep columns term, logPadj_0_12, logPadj_0_60\n",
    "        df = df[['Term', 'logPadj_0_12', 'logPadj_0_60']]\n",
    "        \n",
    "        df = df.loc[df.Term.isin(sig_terms_df1) | df.Term.isin(sig_terms_df2)]\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        # sort df based on the mean of logPadj_0_12 and logPadj_0_60, without writing over df\n",
    "        df = df.loc[df.iloc[:,[1,2]].max(axis=1).sort_values(ascending=True).index]\n",
    "\n",
    "        if i == 0:\n",
    "            # remove \" (GO):$\" from term\n",
    "            df['Term'] = [\"\".join(term.split(\"(GO\")[0]) for term in df.Term]\n",
    "        if i == 2:\n",
    "            df['Term'] = [\" \".join(term.split(\" \")[:-3]) for term in df.Term]\n",
    "        comparison_dfs.append(df)\n",
    "\n",
    "    return comparison_dfs\n",
    "\n",
    "\n",
    "def merge_terms(df_list: list):\n",
    "    pathways = []\n",
    "    for df in df_list:\n",
    "        sig_terms = df.loc[df['Adjusted P-value'] <= 0.05].Term.unique()\n",
    "        pathways += list(sig_terms)\n",
    "    return list(set(pathways))\n",
    "\n",
    "\n",
    "def merge_enrs_into_common_df_2(res_list : list, names : list = None):\n",
    "    comparison_dfs = []\n",
    "    n_pathways = len(res_list[0])\n",
    "\n",
    "    for i in range(n_pathways):\n",
    "        df_list_toMergeTerms = []\n",
    "        for res in res_list:\n",
    "            curr_df = res[i].results\n",
    "            curr_df = curr_df.loc[curr_df['Adjusted P-value'] <= 0.05]\n",
    "            df_list_toMergeTerms.append(curr_df)\n",
    "    \n",
    "        merged_terms = merge_terms(df_list_toMergeTerms)\n",
    "\n",
    "        db_dfs = []\n",
    "        for resIdx, res in enumerate(res_list):\n",
    "            curr_df = res[i].results\n",
    "            curr_df = curr_df.loc[curr_df['Term'].isin(merged_terms)]\n",
    "            curr_df.reset_index(drop=True, inplace=True)\n",
    "            curr_df.loc[:, 'logPadj'] = -np.log10(curr_df['Adjusted P-value'])\n",
    "            curr_df.sort_values(by='logPadj', inplace=True, ascending=False)\n",
    "            if names is not None:\n",
    "                curr_df['whichRes'] = names[resIdx]\n",
    "            else:\n",
    "                curr_df['whichRes'] = resIdx\n",
    "        \n",
    "            if i == 0:\n",
    "                curr_df['Term'] = [\"\".join(term.split(\"(GO\")[0]) for term in curr_df.Term]\n",
    "            if i == list(range(n_pathways))[-1]:\n",
    "                curr_df['Term'] = [\" \".join(term.split(\" \")[:-3]) for term in curr_df.Term]\n",
    "\n",
    "            db_dfs.append(curr_df)\n",
    "\n",
    "        df = pd.concat(db_dfs, axis=0)\n",
    "        comparison_dfs.append(df)\n",
    "\n",
    "    # for comp_df in comparison_dfs:\n",
    "    #     if len(list(set(comp_df.groupby('whichRes').count().Term.values))) != 1 and len(comp_df) != 0:\n",
    "    #         print(comp_df)\n",
    "    #         print(\"WARNING: different number of terms in different results\")\n",
    "    #         return None\n",
    "\n",
    "    comparison_dfs_reformat = []\n",
    "    for comp_df in comparison_dfs:\n",
    "        comp_df.sort_values(by=['Term', 'logPadj'], inplace=True, ascending=False)\n",
    "\n",
    "        comp_df = comp_df.pivot(index='Term', columns='whichRes', values='logPadj')\n",
    "        comp_df['Term'] = comp_df.index\n",
    "        # nColumns = len(comp_df.columns) - 1\n",
    "        # comp_df = comp_df.loc[comp_df.iloc[:,:nColumns].max(axis=1).sort_values(ascending=True).index]\n",
    "\n",
    "        comp_df.Term = [split_text_into_lines(term) for term in comp_df.Term]\n",
    "        comparison_dfs_reformat.append(comp_df)\n",
    "\n",
    "    return comparison_dfs_reformat\n",
    "\n",
    "def split_text_into_lines(text, max_line_length=30):\n",
    "    # split text into lines, but it should not split words\n",
    "    lines = []\n",
    "    words = text.split(\" \")\n",
    "    line = \"\"\n",
    "    for word in words:\n",
    "        if len(line) + len(word) <= max_line_length:\n",
    "            line += word + \" \"\n",
    "        else:\n",
    "            lines.append(line)\n",
    "            line = word + \" \"\n",
    "    lines.append(line)  # append the last line\n",
    "    return \"\\n\".join([line[:-1] for line in lines])  # remove last space from all\n",
    "\n",
    "def write_results(res, out):\n",
    "    df= res.results.sort_values('Adjusted P-value')\n",
    "    df = df.loc[df['Adjusted P-value'] <= 0.05]\n",
    "    if len(df) != 0:\n",
    "        df.to_csv(out, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchors(regions_file):\n",
    "    regions_bedpe =  pd.read_csv(regions_file, sep=\"\\t\")\n",
    "    fivePrime_anchors = regions_bedpe[['chrom1', 'start1', 'end1']]\n",
    "    fivePrime_anchors.columns = ['chrom', 'start', 'end']\n",
    "    threePrime_anchors = regions_bedpe[['chrom2', 'start2', 'end2']]\n",
    "    threePrime_anchors.columns = ['chrom', 'start', 'end']\n",
    "    regions = pd.concat([fivePrime_anchors, threePrime_anchors], axis=0).drop_duplicates().reset_index(drop=True)\n",
    "    regions.drop_duplicates(inplace=True)\n",
    "    return regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gather anchors from the loops because there might be shared anchors between loops\n",
    "And there is a possibilty that a gene is regulated by other pair, that is not present in unique anchors (to a timepoint) list\n",
    "However, we can use the unique anchors to a timepoint to estimate differential TF binding, which is another analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "degs_0_12 = pd.read_csv(\"/home/carlos/oldies/manuscripts/notebooks/RNA/t0-t12.degs.tsv\", sep=\"\\t\")\n",
    "degs_0_60 = pd.read_csv(\"/home/carlos/oldies/manuscripts/notebooks/RNA/t0-t60.degs.tsv\", sep=\"\\t\")\n",
    "degs_0_30 = pd.read_csv(\"/home/carlos/oldies/manuscripts/notebooks/RNA/t0-t30.degs.tsv\", sep=\"\\t\")\n",
    "\n",
    "deseq_lrt = pd.read_csv(\"/home/carlos/oldies/manuscripts/notebooks/RNA/all_deseq_lrt.tsv\", sep=\"\\t\")\n",
    "deseq_lrt.rename(columns={'gene_id': 'ensembl_gene_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search specific genes\n",
    "gene_oi_ENS = \"ENSG00000012061\"\n",
    "df_curr = genes.loc[genes.gene_id == gene_oi_ENS]\n",
    "if df_curr.strand.to_list()[0] == \"-\":\n",
    "    chr_name = df_curr.chrom.to_list()[0]\n",
    "    start = int(df_curr.end.to_list()[0]) // 10_000 * 10_000\n",
    "    end = start + 10_000\n",
    "elif df_curr.strand.to_list()[0] == \"+\":\n",
    "    chr_name = df_curr.chrom.to_list()[0]\n",
    "    start = int(df_curr.start.to_list()[0]) // 10_000 * 10_000\n",
    "    end = start + 10_000\n",
    "\n",
    "comp_labels = [\"comp1\", \"comp2\", \"comp3\", \"comp4\"]\n",
    "comp_files = [\"t0_t12_results_0_0\", \"t0_t12_results_0_1\", \"t0_t12_results_1_0\", \"t0_t12_results_1_1\"]\n",
    "\n",
    "for label, comp in zip(comp_labels, comp_files):\n",
    "    regions = pd.read_csv(f\"/home/carlos/oldies/manuscripts/notebooks/gnn/{comp}.tsv\", sep=\"\\t\")\n",
    "\n",
    "    oi_df = regions.loc[(regions.chrom == chr_name) & (regions.start == start)]\n",
    "    if len(oi_df) > 0:\n",
    "        print(f\"Processing {label}\")\n",
    "        print(oi_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gnn res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [f\"/home/carlos/oldies/manuscripts/notebooks/gnn/t0_t12_results_{comp_now}.tsv\" for comp_now in [\"0_0\", \"1_0\", \"0_1\", \"1_1\"]]\n",
    "all_dfs = [pd.read_csv(df, sep=\"\\t\") for df in paths] \n",
    "all_regions = pd.concat(all_dfs) # This is the GNN evaluated regions\n",
    "all_regions = all_regions.iloc[:, :3]\n",
    "universe_3d_df = bioframe.overlap(all_regions, genes, how='inner')\n",
    "universe_3d_ids = list(universe_3d_df.gene_id_.dropna().unique())\n",
    "universe_3d_names = list(universe_3d_df.external_gene_name_.dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_labels = [\"comp1\", \"comp2\", \"comp3\", \"comp4\"]\n",
    "comp_files = [\"t0_t12_results_0_0\", \"t0_t12_results_0_1\", \"t0_t12_results_1_0\", \"t0_t12_results_1_1\"]\n",
    "\n",
    "\n",
    "filter_11 = False\n",
    "for label, comp in zip(comp_labels, comp_files):\n",
    "    regions = pd.read_csv(f\"/home/carlos/oldies/manuscripts/notebooks/gnn/{comp}.tsv\", sep=\"\\t\")\n",
    "    filter_w_unibind = False\n",
    "\n",
    "    unibind_mapping = {\n",
    "        \"0_1\": \"0_1_vs_1_0\",\n",
    "        \"1_0\": \"1_0_vs_0_1\",\n",
    "        \"0_0\": \"0_0_vs_1_1\",\n",
    "        \"1_1\": \"1_1_vs_0_0\"\n",
    "    }\n",
    "\n",
    "    comp_name = comp[-3:]\n",
    "    if comp_name == \"1_1\" and filter_11:\n",
    "        regions = regions.loc[(regions[\"t0_q30-t12_q30\"] == 0) & (regions[\"t12_q30-t0_q30\"] == 0)]\n",
    "\n",
    "    if filter_w_unibind:\n",
    "        unibind_regions = pd.read_csv(f\"/home/carlos/oldies/manuscripts/notebooks/unibind/gnn_res/gnn_{unibind_mapping[comp_name]}/extracted_regions_merged.bed\", sep=\"\\t\", header=None).iloc[:, :3]\n",
    "        unibind_regions.columns = ['chrom', 'start', 'end']\n",
    "        unibind_regions.start = unibind_regions.start.astype(int)\n",
    "        unibind_regions.end = unibind_regions.end.astype(int)\n",
    "        regions = bioframe.overlap(regions, unibind_regions, how='inner')\n",
    "\n",
    "\n",
    "    degs_0_12_degs, uni = overlapper(degs_0_12, regions, genes)\n",
    "    degs_0_30_degs, uni = overlapper(degs_0_30, regions, genes)\n",
    "    degs_0_60_degs, uni = overlapper(degs_0_60, regions, genes)\n",
    "\n",
    "    uni.to_csv(f\"gnn_enrichr_results_comp_wise/{label}_universe.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "    res_0_12 = enrichrrr(degs_0_12_degs, pathways, universe_3d_names)\n",
    "    res_0_30 = enrichrrr(degs_0_30_degs, pathways, universe_3d_names)\n",
    "    res_0_60 = enrichrrr(degs_0_60_degs, pathways, universe_3d_names)\n",
    "\n",
    "    comparison_dfs = merge_enrs_into_common_df_2([res_0_12, res_0_30, res_0_60], [\"0_12\", \"0_30\", \"0_60\"])\n",
    "\n",
    "    for res1, res2, res3, pathway in zip(res_0_12, res_0_30, res_0_60, pathways):\n",
    "        write_results(res1, f\"gnn_enrichr_results_comp_wise/{label}_{pathway}_0_12.tsv\")\n",
    "        write_results(res2, f\"gnn_enrichr_results_comp_wise/{label}_{pathway}_0_30.tsv\")\n",
    "        write_results(res3, f\"gnn_enrichr_results_comp_wise/{label}_{pathway}_0_60.tsv\")\n",
    "\n",
    "    database_names = [\"Gene Ontology\\nBiological Process\", \"MSigDB\\nHallmark\", \"NCI-Nature\\nPID\"]\n",
    "    \n",
    "    plot_count = 0\n",
    "    for i, (df, pathway) in enumerate(zip(comparison_dfs, pathways)):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "        if len(df) != 0:\n",
    "\n",
    "            df = df.loc[df.iloc[:,[0,1,2]].max(axis=1).sort_values(ascending=True).index]\n",
    "            df = df.iloc[-20:, :]\n",
    "            b = df.plot.barh(x='Term', ax=ax, color=['#A63446', \"#F5B841\", '#9DBBAE'])\n",
    "            b.axvline(x=-np.log10(0.05), color='black', linestyle='--', alpha=0.6, linewidth=3)\n",
    "            b.set_xlabel(f'-log$_{{10}}$(Adjusted P-value)', fontsize=20)\n",
    "\n",
    "            b.axvline(x=-np.log10(0.05), color='black', linestyle='--', alpha=.9, linewidth=3)\n",
    "\n",
    "            b.set_xlabel(f'-log$_{{10}}$ Adjusted P-value', fontsize=12)\n",
    "            b.set_ylabel(database_names[i], fontsize=20)\n",
    "\n",
    "            \n",
    "            # change font size of x and y ticks\n",
    "            b.tick_params(labelsize=8)\n",
    "            b.tick_params(axis='both', which='major', labelsize=10)\n",
    "            b.tick_params(axis='both', which='minor', labelsize=10)\n",
    "\n",
    "            db_name = database_names[i].replace(\"\\n\", \"_\")\n",
    "\n",
    "            #fig.suptitle(f\"{label}\", fontsize=30)\n",
    "            fig.set_tight_layout(True)\n",
    "            fig.savefig(f\"gnn_enrichr_results_comp_wise/{label}_{db_name}_pathways.svg\")\n",
    "            fig.savefig(f\"gnn_enrichr_results_comp_wise/{label}_{db_name}_pathways.png\", dpi=300, facecolor=\"white\", edgecolor='none')\n",
    "\n",
    "        fig.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp_files = [\"t0_t12_results_0_0\", \"t0_t12_results_0_1\", \"t0_t12_results_1_0\", \"t0_t12_results_1_1\"]\n",
    "\n",
    "# #regions = pd.concat([pd.read_csv(f\"/home/carlos/oldies/manuscripts/notebooks/gnn/{comp}.tsv\", sep=\"\\t\") for comp in comp_files[:3]]) # combine comp1, comp2, comp3\n",
    "# #label = \"changed_regions\"\n",
    "# regions = pd.concat([pd.read_csv(f\"/home/carlos/oldies/manuscripts/notebooks/gnn/{comp}.tsv\", sep=\"\\t\") for comp in comp_files[3:]])\n",
    "# label = \"unchanged_regions\"\n",
    "\n",
    "# degs_0_12_degs, _ = overlapper(degs_0_12, regions, genes)\n",
    "# degs_0_30_degs, _ = overlapper(degs_0_30, regions, genes)\n",
    "# degs_0_60_degs, _ = overlapper(degs_0_60, regions, genes)\n",
    "\n",
    "# res_0_12 = enrichrrr(degs_0_12_degs, pathways, universe_3d_names)\n",
    "# res_0_30 = enrichrrr(degs_0_30_degs, pathways, universe_3d_names)\n",
    "# res_0_60 = enrichrrr(degs_0_60_degs, pathways, universe_3d_names)\n",
    "\n",
    "# comparison_dfs = merge_enrs_into_common_df_2([res_0_12, res_0_30, res_0_60], [\"0_12\", \"0_30\", \"0_60\"])\n",
    "\n",
    "# for res1, res2, res3, pathway in zip(res_0_12, res_0_30, res_0_60, pathways):\n",
    "#     write_results(res1, f\"gnn_enrichr_results_all_vs_all/{label}_{pathway}_0_12.tsv\")\n",
    "#     write_results(res2, f\"gnn_enrichr_results_all_vs_all/{label}_{pathway}_0_30.tsv\")\n",
    "#     write_results(res3, f\"gnn_enrichr_results_all_vs_all/{label}_{pathway}_0_60.tsv\")\n",
    "\n",
    "# fig, ax = plt.subplots(3, 1, figsize=(10, 20))\n",
    "# plot_count = 0\n",
    "# for i, (df, pathway) in enumerate(zip(comparison_dfs, pathways)):\n",
    "\n",
    "#     if len(df) != 0:\n",
    "#         df = df.loc[df.iloc[:,[0,1,2]].mean(axis=1).sort_values(ascending=True).index]\n",
    "#         df = df.iloc[-20:, :]\n",
    "#         plot_count += 1\n",
    "#         b = df.plot.barh(x='Term', ax=ax[i], color=['#A63446', \"#F5B841\", '#9DBBAE'])\n",
    "\n",
    "#         b.axvline(x=-np.log10(0.05), color='black', linestyle='--', alpha=0.6, linewidth=3)\n",
    "#         b.set_xlabel(f'-log$_{{10}}$(Adjusted P-value)', fontsize=20)\n",
    "#         b.set_ylabel(f'{pathway} Term', fontsize=20)\n",
    "\n",
    "#     if plot_count != 0:\n",
    "#         fig.suptitle(f\"{label}\", fontsize=30)\n",
    "#         fig.set_tight_layout(True)\n",
    "#         fig.savefig(f\"gnn_enrichr_results_all_vs_all/{label}_pathways.svg\")\n",
    "#         fig.savefig(f\"gnn_enrichr_results_all_vs_all/{label}_pathways.png\", dpi=300, facecolor=\"white\", edgecolor='none')\n",
    "\n",
    "#         fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNN plot all vs all / Uniq Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_dfs_all_vs_all = []\n",
    "\n",
    "comp_files = [\"t0_t12_results_0_0\", \"t0_t12_results_0_1\", \"t0_t12_results_1_0\", \"t0_t12_results_1_1\"]\n",
    "\n",
    "regions = pd.concat([pd.read_csv(f\"/home/carlos/oldies/manuscripts/notebooks/gnn/{comp}.tsv\", sep=\"\\t\") for comp in comp_files[:3]]) # combine comp1, comp2, comp3\n",
    "label = \"changed_regions\"\n",
    "\n",
    "\n",
    "degs_0_12_degs, _ = overlapper(degs_0_12, regions, genes)\n",
    "degs_0_30_degs, _ = overlapper(degs_0_30, regions, genes)\n",
    "degs_0_60_degs, _ = overlapper(degs_0_60, regions, genes)\n",
    "\n",
    "res_0_12 = enrichrrr(degs_0_12_degs, pathways, universe_3d_names)\n",
    "res_0_30 = enrichrrr(degs_0_30_degs, pathways, universe_3d_names)\n",
    "res_0_60 = enrichrrr(degs_0_60_degs, pathways, universe_3d_names)\n",
    "\n",
    "for res1, res2, res3, pathway in zip(res_0_12, res_0_30, res_0_60, pathways):\n",
    "    write_results(res1, f\"gnn_enrichr_results_all_vs_all/{label}_{pathway}_0_12.tsv\")\n",
    "    write_results(res2, f\"gnn_enrichr_results_all_vs_all/{label}_{pathway}_0_30.tsv\")\n",
    "    write_results(res3, f\"gnn_enrichr_results_all_vs_all/{label}_{pathway}_0_60.tsv\")\n",
    "\n",
    "comparison_dfs = merge_enrs_into_common_df_2([res_0_12, res_0_30, res_0_60], [\"0_12\", \"0_30\", \"0_60\"])\n",
    "\n",
    "comparison_dfs_all_vs_all.append(comparison_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = pd.concat([pd.read_csv(f\"/home/carlos/oldies/manuscripts/notebooks/gnn/{comp}.tsv\", sep=\"\\t\") for comp in comp_files[3:]])\n",
    "label = \"unchanged_regions\"\n",
    "\n",
    "degs_0_12_degs, _ = overlapper(degs_0_12, regions, genes)\n",
    "degs_0_30_degs, _ = overlapper(degs_0_30, regions, genes)\n",
    "degs_0_60_degs, _ = overlapper(degs_0_60, regions, genes)\n",
    "\n",
    "res_0_12 = enrichrrr(degs_0_12_degs, pathways, universe_3d_names)\n",
    "res_0_30 = enrichrrr(degs_0_30_degs, pathways, universe_3d_names)\n",
    "res_0_60 = enrichrrr(degs_0_60_degs, pathways, universe_3d_names)\n",
    "\n",
    "for res1, res2, res3, pathway in zip(res_0_12, res_0_30, res_0_60, pathways):\n",
    "    write_results(res1, f\"gnn_enrichr_results_all_vs_all/{label}_{pathway}_0_12.tsv\")\n",
    "    write_results(res2, f\"gnn_enrichr_results_all_vs_all/{label}_{pathway}_0_30.tsv\")\n",
    "    write_results(res3, f\"gnn_enrichr_results_all_vs_all/{label}_{pathway}_0_60.tsv\")\n",
    "\n",
    "comparison_dfs = merge_enrs_into_common_df_2([res_0_12, res_0_30, res_0_60], [\"0_12\", \"0_30\", \"0_60\"])\n",
    "comparison_dfs_all_vs_all.append(comparison_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_names = [\"Gene Ontology\\nBiological Process\", \"MSigDB\\nHallmark\", \"NCI-Nature\\nPID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changed regions uniq terms\n",
    "\n",
    "\n",
    "for idx, (changed, notChanged) in enumerate(zip(comparison_dfs_all_vs_all[0], comparison_dfs_all_vs_all[1])):\n",
    "    fig , ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "    # find common terms \n",
    "    common_terms = list(set(changed.index).intersection(set(notChanged.index)))\n",
    "    # remove common terms from changed \n",
    "    df = changed.loc[~changed.index.isin(common_terms)]\n",
    "    df = df.loc[df.iloc[:,[0,1,2]].max(axis=1).sort_values(ascending=True).index]\n",
    "\n",
    "    if len(df) != 0:\n",
    "        df = df.iloc[-15:, :]\n",
    "        df.columns = ['12min', '30min', '60min', 'Term']\n",
    "        b = df.plot.barh(x='Term', ax=ax, color=['#A63446', \"#F5B841\", '#9DBBAE'])\n",
    "        b.axvline(x=-np.log10(0.05), color='black', linestyle='--', alpha=.9, linewidth=3)\n",
    "\n",
    "        b.set_xlabel(f'-log$_{{10}}$ Adjusted P-value', fontsize=12)\n",
    "        b.set_ylabel(database_names[idx], fontsize=20)\n",
    "\n",
    "        \n",
    "        # change font size of x and y ticks\n",
    "        b.tick_params(labelsize=8)\n",
    "        b.tick_params(axis='both', which='major', labelsize=10)\n",
    "        b.tick_params(axis='both', which='minor', labelsize=10)\n",
    "\n",
    "        db_name = database_names[idx].replace(\"\\n\", \"_\")\n",
    "        df.to_csv(f\"gnn_enrichr_results_all_vs_all_uc/{db_name}_pathways_changed_uniq_terms.tsv\", sep='\\t', index=False)\n",
    "        fig.set_tight_layout(True)\n",
    "        fig.savefig(f\"gnn_enrichr_results_all_vs_all_uc/{db_name}_pathways_changed_uniq_terms.svg\")\n",
    "        fig.savefig(f\"gnn_enrichr_results_all_vs_all_uc/{db_name}_pathways_changed_uniq_terms.png\", dpi=300, facecolor=\"white\", edgecolor='none')\n",
    "\n",
    "    fig.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unchanged regions uniq terms\n",
    "\n",
    "for idx, (changed, notChanged) in enumerate(zip(comparison_dfs_all_vs_all[0], comparison_dfs_all_vs_all[1])):\n",
    "    fig , ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "    common_terms = list(set(changed.index).intersection(set(notChanged.index)))\n",
    "    # remove common terms from changed \n",
    "    df = notChanged.loc[~notChanged.index.isin(common_terms)]\n",
    "    if len(df) != 0:\n",
    "        df = df.loc[df.iloc[:,[0,1,2]].max(axis=1).sort_values(ascending=True).index]\n",
    "\n",
    "\n",
    "    if len(df) != 0:\n",
    "        df = df.iloc[-15:, :]\n",
    "        df.columns = ['12min', '30min', '60min', 'Term']\n",
    "        b = df.plot.barh(x='Term', ax=ax, color=['#A63446', \"#F5B841\", '#9DBBAE'])\n",
    "        b.axvline(x=-np.log10(0.05), color='black', linestyle='--', alpha=.9, linewidth=3)\n",
    "\n",
    "        b.set_xlabel(f'-log$_{{10}}$ Adjusted P-value', fontsize=12)\n",
    "        b.set_ylabel(database_names[idx], fontsize=20)\n",
    "\n",
    "        \n",
    "        # change font size of x and y ticks\n",
    "        b.tick_params(labelsize=8)\n",
    "        b.tick_params(axis='both', which='major', labelsize=10)\n",
    "        b.tick_params(axis='both', which='minor', labelsize=10)\n",
    "\n",
    "        db_name = database_names[idx].replace(\"\\n\", \"_\")\n",
    "        df.to_csv(f\"gnn_enrichr_results_all_vs_all_uc/{db_name}_pathways_unchanged_uniq_terms.tsv\", sep='\\t', index=False)\n",
    "        fig.set_tight_layout(True)\n",
    "        fig.savefig(f\"gnn_enrichr_results_all_vs_all_uc/{db_name}_pathways_unchanged_uniq_terms.svg\")\n",
    "        fig.savefig(f\"gnn_enrichr_results_all_vs_all_uc/{db_name}_pathways_unchanged_uniq_terms.png\", dpi=300, facecolor=\"white\", edgecolor='none')\n",
    "    \n",
    "    fig.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changed regions common terms\n",
    "for idx, (changed, notChanged) in enumerate(zip(comparison_dfs_all_vs_all[0], comparison_dfs_all_vs_all[1])):\n",
    "    fig , ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "    common_terms = list(set(changed.index).intersection(set(notChanged.index)))\n",
    "\n",
    "    df = changed.loc[changed.index.isin(common_terms)]\n",
    "\n",
    "    if len(df) != 0:\n",
    "        df = df.loc[df.iloc[:,[0,1,2]].max(axis=1).sort_values(ascending=True).index]\n",
    "    \n",
    "    if len(df) != 0:\n",
    "        df = df.iloc[-15:, :]\n",
    "        df.columns = ['12min', '30min', '60min', 'Term']\n",
    "        b = df.plot.barh(x='Term', ax=ax, color=['#A63446', \"#F5B841\", '#9DBBAE'])\n",
    "        b.axvline(x=-np.log10(0.05), color='black', linestyle='--', alpha=.9, linewidth=3)\n",
    "\n",
    "        b.set_xlabel(f'-log$_{{10}}$ Adjusted P-value', fontsize=12)\n",
    "        b.set_ylabel(database_names[idx], fontsize=20)\n",
    "\n",
    "        \n",
    "        # change font size of x and y ticks\n",
    "        b.tick_params(labelsize=8)\n",
    "        b.tick_params(axis='both', which='major', labelsize=12)\n",
    "        b.tick_params(axis='both', which='minor', labelsize=12)\n",
    "        \n",
    "        db_name = database_names[idx].replace(\"\\n\", \"_\")\n",
    "        df.to_csv(f\"gnn_enrichr_results_all_vs_all_uc/{db_name}_pathways_changed_common_terms.tsv\", sep='\\t', index=False)\n",
    "        fig.set_tight_layout(True)\n",
    "        fig.savefig(f\"gnn_enrichr_results_all_vs_all_uc/{db_name}_pathways_changed_common_terms.svg\")\n",
    "        fig.savefig(f\"gnn_enrichr_results_all_vs_all_uc/{db_name}_pathways_changed_common_terms.png\", dpi=300, facecolor=\"white\", edgecolor='none')\n",
    "    \n",
    "    fig.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not Changed regions common terms\n",
    "for idx, (changed, notChanged) in enumerate(zip(comparison_dfs_all_vs_all[0], comparison_dfs_all_vs_all[1])):\n",
    "    fig , ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "    common_terms = list(set(changed.index).intersection(set(notChanged.index)))\n",
    "    # remove common terms from changed \n",
    "    df = notChanged.loc[notChanged.index.isin(common_terms)]\n",
    "\n",
    "    if len(df) != 0:\n",
    "        df = df.loc[df.iloc[:,[0,1,2]].max(axis=1).sort_values(ascending=True).index]\n",
    "    \n",
    "    if len(df) != 0:\n",
    "        df = df.iloc[-15:, :]\n",
    "        df.columns = ['12min', '30min', '60min', 'Term']\n",
    "        b = df.plot.barh(x='Term', ax=ax, color=['#A63446', \"#F5B841\", '#9DBBAE'])\n",
    "        b.axvline(x=-np.log10(0.05), color='black', linestyle='--', alpha=.9, linewidth=3)\n",
    "\n",
    "        b.set_xlabel(f'-log$_{{10}}$ Adjusted P-value', fontsize=12)\n",
    "        b.set_ylabel(database_names[idx], fontsize=20)\n",
    "\n",
    "        \n",
    "        # change font size of x and y ticks\n",
    "        b.tick_params(labelsize=8)\n",
    "        b.tick_params(axis='both', which='major', labelsize=12)\n",
    "        b.tick_params(axis='both', which='minor', labelsize=12)\n",
    "        db_name = database_names[idx].replace(\"\\n\", \"_\")\n",
    "\n",
    "        fig.set_tight_layout(True)\n",
    "        df.to_csv(f\"gnn_enrichr_results_all_vs_all_uc/{db_name}_pathways_unchanged_common_terms.tsv\", sep='\\t', index=False)\n",
    "        fig.savefig(f\"gnn_enrichr_results_all_vs_all_uc/{db_name}_pathways_unchanged_common_terms.svg\")\n",
    "        fig.savefig(f\"gnn_enrichr_results_all_vs_all_uc/{db_name}_pathways_unchanged_common_terms.png\", dpi=300, facecolor=\"white\", edgecolor='none')\n",
    "    \n",
    "    fig.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNN res, expression profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_geneID_to_name(geneID):\n",
    "    if geneID not in genes.gene_id.values:\n",
    "        return None\n",
    "    return genes.loc[genes.gene_id == geneID].external_gene_name.values[0]\n",
    "\n",
    "def map_txID_to_name(txID):\n",
    "    if txID not in genes.tx_id.values:\n",
    "        return None\n",
    "    return genes.loc[genes.tx_id == txID].external_gene_name.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['SU_100', 'SU_200', 'SU_300', 'SU_112', 'SU_212', 'SU_312', 'SU_130', 'SU_230', 'SU_330', 'SU_160', 'SU_260', 'SU_360']\n",
    "\n",
    "df = pd.read_csv(f\"/home/carlos/oldies/projects/rna-seq/quant/SU_100/quant.sf\", sep=\"\\t\")\n",
    "df.Name = df.Name.apply(lambda x: x.split(\".\")[0])\n",
    "df = df.loc[df.Name.isin(genes.tx_id.values)]\n",
    "mapped_names = [map_txID_to_name(txID.split(\".\")[0]) for txID in df.Name.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = []\n",
    "\n",
    "for name in order:\n",
    "    df = pd.read_csv(f\"/home/carlos/oldies/projects/rna-seq/quant/{name}/quant.sf\", sep=\"\\t\")\n",
    "    df.Name = df.Name.apply(lambda x: x.split(\".\")[0])\n",
    "    df = df.loc[df.Name.isin(genes.tx_id.values)]\n",
    "    df.rename(columns={'TPM': name}, inplace=True)\n",
    "    series.append(df[name])\n",
    "\n",
    "tcounts_df = pd.DataFrame(series).T\n",
    "\n",
    "tcounts_df['geneName'] = mapped_names\n",
    "\n",
    "for i, name in zip([0, 3, 6, 9], [\"Control\", \"12min\", \"30min\", \"60min\"]):\n",
    "    tcounts_df[name] = tcounts_df.iloc[:, i : i + 3].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which_Genes = [\n",
    "#     \"ATF2\", \"ATF3\", \"ATF4\", \n",
    "#     \"JUN\", \"JUNB\", \"JUND\",\n",
    "#     \"FOS\", \"FOSL1\", \"FOSL2\", \"FOSB\", \n",
    "#     \"MAF\", \"MAFB\",\n",
    "#     \"TP53\"]\n",
    "\n",
    "which_Genes = \"SURF1;POLH;GTF2B;ADCY6;BRF2;PRIM1;DGUOK;RNMT;SEC61A1;ZWINT;POLD1;RBX1;CDA;NELFE;RFC4\".split(\";\")\n",
    "plot_df = {\n",
    "    \"geneName\": [],\n",
    "    \"Mean\": [],\n",
    "    \"time\": []\n",
    "}\n",
    "\n",
    "for gene_oi in which_Genes:\n",
    "    for name in [\"Control\", \"12min\", \"30min\", \"60min\"]:\n",
    "        plot_df[\"geneName\"].append(gene_oi)\n",
    "        plot_df[\"Mean\"].append(tcounts_df.loc[tcounts_df.geneName == gene_oi, name].values[0])\n",
    "        plot_df[\"time\"].append(name)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10), ncols=len(which_Genes))\n",
    "plot_df = pd.DataFrame(plot_df)\n",
    "for i, gene_oi in enumerate(which_Genes):\n",
    "    sns.barplot(x=\"time\", y=\"Mean\", data=plot_df.loc[plot_df.geneName == gene_oi], ax=ax[i])\n",
    "    ax[i].set_title(gene_oi)\n",
    "    ax[i].set_ylabel(\"Mean TPM\")\n",
    "    ax[i].set_xlabel(\"Time\")\n",
    "    ax[i].set_xticklabels(ax[i].get_xticklabels(), rotation=45, horizontalalignment='right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
