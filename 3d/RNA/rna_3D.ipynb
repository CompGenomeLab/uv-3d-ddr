{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioframe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gseapy as gp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import glob\n",
    "import cooler\n",
    "#bm = gp.Biomart()\n",
    "\n",
    "pd.options.mode.chained_assignment = None # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions and files ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read gtf\n",
    "gtf = \"/home/carlos/Desktop/manuscripts/notebooks/unibind/GRCh38.gtf\"\n",
    "genes_all = bioframe.read_table(gtf, schema='gtf').query('feature==\"CDS\"')\n",
    "genes_all.start = genes_all.start.astype(int)\n",
    "genes_all.end = genes_all.end.astype(int)\n",
    "genes_all.sort_values(by=['chrom', 'start'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use appris or mane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/carlos/Desktop/manuscripts/notebooks/RNA/appris_data.appris.txt\", sep='\\t')\n",
    "df = df.loc[df[\"MANE\"].isin(['MANE_Select'])] #, 'MANE_Plus_Clinical'])]\n",
    "mane_tx_list = df['Transcript ID'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = genes_all.copy()\n",
    "genes['gene_id'] = [gene_id.split(\".\")[0] for gene_id in genes.attributes.str.extract(r'gene_id \"(.*?)\";', expand=False)]\n",
    "genes['tx_id'] = [tx_id.split(\".\")[0] for tx_id in genes.attributes.str.extract(r'transcript_id \"(.*?)\";', expand=False)]\n",
    "genes['external_gene_name'] = [gene_name.split(\".\")[0] for gene_name in genes.attributes.str.extract(r'gene_name \"(.*?)\";', expand=False)]\n",
    "genes = genes.loc[genes['tx_id'].isin(mane_tx_list)]\n",
    "genes.sort_values(by=['chrom', 'start'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_adjusted = []\n",
    "for tx_id, tx_df in genes.groupby('tx_id').__iter__():\n",
    "    if \"+\" in tx_df.strand.to_list():\n",
    "        tx_adjusted.append(tx_df.iloc[0, :])\n",
    "    elif \"-\" in tx_df.strand.to_list():\n",
    "        tx_adjusted.append(tx_df.iloc[-1, :])\n",
    "\n",
    "genes = pd.concat(tx_adjusted, axis=1).T\n",
    "genes.reset_index(drop=True, inplace=True)\n",
    "genes.start = genes.start.astype(int)\n",
    "genes.end = genes.end.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human = pd.Series(gp.get_library_name(organism='Human'))\n",
    "pathways = human.loc[human.str.contains(\"MSigDB_Hallmark_2020\") | human.str.contains(\"GO_Biological_Process_2023\") | human.str.contains(\"NCI-Nature_2016\")].reset_index(drop=True)\n",
    "#pathways = human.loc[human.str.contains(\"MSigDB_Hallmark_2020\") | human.str.contains(\"NCI-Nature_2016\") ].reset_index(drop=True)\n",
    "pathways = {\n",
    "    pathway: gp.get_library(name=pathway, organism='Human')\n",
    "    for pathway in pathways\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrichrrr(\n",
    "    degs_list: list, \n",
    "    pathways_dict: dict, \n",
    "    universe_list: list = None):\n",
    "    results = []\n",
    "\n",
    "    for pathway_name, gene_sets in pathways_dict.items():\n",
    "        enr = gp.enrichr(gene_list=degs_list,\n",
    "                     gene_sets=gene_sets,\n",
    "                     #gene_sets = pathway_name,\n",
    "                     outdir=None,\n",
    "                     background=universe_list,\n",
    "                     verbose=False)\n",
    "        results.append(enr)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlapper(\n",
    "    current_degs_df: pd.DataFrame, \n",
    "    my_regions_df: pd.DataFrame, \n",
    "    all_genes: pd.DataFrame, \n",
    "    tss_coord_only: bool = True, # True if you want to use only the TSS coordinates (point-wise), False if you want to create a window around the TSS\n",
    "    upstream: int =2000, \n",
    "    downstream: int =500,\n",
    "    returnNames = True):\n",
    "    strand_oriented_genes = all_genes.copy()\n",
    "\n",
    "    if tss_coord_only == True:\n",
    "        strand_oriented_genes['start'] = all_genes.apply(lambda x: x['start'] if x['strand'] == \"+\" else x['end'], axis=1)\n",
    "        strand_oriented_genes['end'] = strand_oriented_genes['start']\n",
    "    else:\n",
    "        strand_oriented_genes['start'] = all_genes.apply(lambda x: x['start'] - upstream if x['strand'] == 1 else x['end'] - downstream, axis=1)\n",
    "        strand_oriented_genes['end'] = all_genes.apply(lambda x: x['start'] + downstream if x['strand'] == 1 else x['end'] + upstream, axis=1)\n",
    "\n",
    "    my_regions_universe = bioframe.overlap(strand_oriented_genes, my_regions_df, how='inner')\n",
    "    degs_filter = current_degs_df.loc[current_degs_df['ensembl_gene_id'].isin(my_regions_universe['gene_id'])]\n",
    "    \n",
    "    if returnNames == True:\n",
    "        return list(degs_filter.external_gene_name.dropna().unique()), my_regions_universe\n",
    "    else:\n",
    "        return degs_filter, my_regions_universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_enrs_into_common_df(res_1, res_2):\n",
    "    comparison_dfs = []\n",
    "\n",
    "    for i, (enr1, enr2) in enumerate(zip(res_1, res_2)):\n",
    "        df1 = enr1.results.sort_values('Adjusted P-value')\n",
    "        df2 = enr2.results.sort_values('Adjusted P-value')\n",
    "        sig_terms_df1 = df1.loc[df1['Adjusted P-value'] <= 0.05].Term\n",
    "        sig_terms_df2 = df2.loc[df2['Adjusted P-value'] <= 0.05].Term\n",
    "        df1['logPadj'] = -np.log10(df1['Adjusted P-value'])\n",
    "        df2['logPadj'] = -np.log10(df2['Adjusted P-value'])\n",
    "        \n",
    "        # merge dfs\n",
    "        df = pd.merge(df1, df2, on='Term', suffixes=('_0_12', '_0_60'))\n",
    "        if i == 2:\n",
    "            df = df.loc[df['logPadj_0_60'] >= 1.3]\n",
    "        # keep columns term, logPadj_0_12, logPadj_0_60\n",
    "        df = df[['Term', 'logPadj_0_12', 'logPadj_0_60']]\n",
    "        \n",
    "        df = df.loc[df.Term.isin(sig_terms_df1) | df.Term.isin(sig_terms_df2)]\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        # sort df based on the mean of logPadj_0_12 and logPadj_0_60, without writing over df\n",
    "        df = df.loc[df.iloc[:,[1,2]].max(axis=1).sort_values(ascending=True).index]\n",
    "\n",
    "        if i == 0:\n",
    "            # remove \" (GO):$\" from term\n",
    "            df['Term'] = [\"\".join(term.split(\"(GO\")[0]) for term in df.Term]\n",
    "        if i == 2:\n",
    "            df['Term'] = [\" \".join(term.split(\" \")[:-3]) for term in df.Term]\n",
    "        comparison_dfs.append(df)\n",
    "\n",
    "    return comparison_dfs\n",
    "\n",
    "\n",
    "def merge_terms(df_list: list):\n",
    "    pathways = []\n",
    "    for df in df_list:\n",
    "        sig_terms = df.loc[df['Adjusted P-value'] <= 0.05].Term.unique()\n",
    "        pathways += list(sig_terms)\n",
    "    return list(set(pathways))\n",
    "\n",
    "\n",
    "def merge_enrs_into_common_df_2(res_list : list, names : list = None):\n",
    "    comparison_dfs = []\n",
    "    n_pathways = len(res_list[0])\n",
    "\n",
    "    for i in range(n_pathways):\n",
    "        df_list_toMergeTerms = []\n",
    "        for res in res_list:\n",
    "            curr_df = res[i].results\n",
    "            curr_df = curr_df.loc[curr_df['Adjusted P-value'] <= 0.05]\n",
    "            df_list_toMergeTerms.append(curr_df)\n",
    "    \n",
    "        merged_terms = merge_terms(df_list_toMergeTerms)\n",
    "\n",
    "        db_dfs = []\n",
    "        for resIdx, res in enumerate(res_list):\n",
    "            curr_df = res[i].results\n",
    "            curr_df = curr_df.loc[curr_df['Term'].isin(merged_terms)]\n",
    "            curr_df.reset_index(drop=True, inplace=True)\n",
    "            curr_df.loc[:, 'logPadj'] = -np.log10(curr_df['Adjusted P-value'])\n",
    "            curr_df.sort_values(by='logPadj', inplace=True, ascending=False)\n",
    "            if names is not None:\n",
    "                curr_df['whichRes'] = names[resIdx]\n",
    "            else:\n",
    "                curr_df['whichRes'] = resIdx\n",
    "        \n",
    "            if i == 0:\n",
    "                curr_df['Term'] = [\"\".join(term.split(\"(GO\")[0]) for term in curr_df.Term]\n",
    "            if i == list(range(n_pathways))[-1]:\n",
    "                curr_df['Term'] = [\" \".join(term.split(\" \")[:-3]) for term in curr_df.Term]\n",
    "\n",
    "            db_dfs.append(curr_df)\n",
    "\n",
    "        df = pd.concat(db_dfs, axis=0)\n",
    "        comparison_dfs.append(df)\n",
    "\n",
    "    # for comp_df in comparison_dfs:\n",
    "    #     if len(list(set(comp_df.groupby('whichRes').count().Term.values))) != 1 and len(comp_df) != 0:\n",
    "    #         print(comp_df)\n",
    "    #         print(\"WARNING: different number of terms in different results\")\n",
    "    #         return None\n",
    "\n",
    "    comparison_dfs_reformat = []\n",
    "    for comp_df in comparison_dfs:\n",
    "        comp_df.sort_values(by=['Term', 'logPadj'], inplace=True, ascending=False)\n",
    "\n",
    "        comp_df = comp_df.pivot(index='Term', columns='whichRes', values='logPadj')\n",
    "        comp_df['Term'] = comp_df.index\n",
    "        # nColumns = len(comp_df.columns) - 1\n",
    "        # comp_df = comp_df.loc[comp_df.iloc[:,:nColumns].max(axis=1).sort_values(ascending=True).index]\n",
    "\n",
    "        comp_df.Term = [split_text_into_lines(term) for term in comp_df.Term]\n",
    "        comparison_dfs_reformat.append(comp_df)\n",
    "\n",
    "    return comparison_dfs_reformat\n",
    "\n",
    "def split_text_into_lines(text, max_line_length=30):\n",
    "    # split text into lines, but it should not split words\n",
    "    lines = []\n",
    "    words = text.split(\" \")\n",
    "    line = \"\"\n",
    "    for word in words:\n",
    "        if len(line) + len(word) <= max_line_length:\n",
    "            line += word + \" \"\n",
    "        else:\n",
    "            lines.append(line)\n",
    "            line = word + \" \"\n",
    "    lines.append(line)  # append the last line\n",
    "    return \"\\n\".join([line[:-1] for line in lines])  # remove last space from all\n",
    "\n",
    "def write_results(res, out):\n",
    "    df= res.results.sort_values('Adjusted P-value')\n",
    "    df = df.loc[df['Adjusted P-value'] <= 0.05]\n",
    "    if len(df) != 0:\n",
    "        df.to_csv(out, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchors(regions_file):\n",
    "    regions_bedpe =  pd.read_csv(regions_file, sep=\"\\t\")\n",
    "    fivePrime_anchors = regions_bedpe[['chrom1', 'start1', 'end1']]\n",
    "    fivePrime_anchors.columns = ['chrom', 'start', 'end']\n",
    "    threePrime_anchors = regions_bedpe[['chrom2', 'start2', 'end2']]\n",
    "    threePrime_anchors.columns = ['chrom', 'start', 'end']\n",
    "    regions = pd.concat([fivePrime_anchors, threePrime_anchors], axis=0).drop_duplicates().reset_index(drop=True)\n",
    "    regions.drop_duplicates(inplace=True)\n",
    "    return regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gather anchors from the loops because there might be shared anchors between loops\n",
    "And there is a possibilty that a gene is regulated by other pair, that is not present in unique anchors (to a timepoint) list\n",
    "However, we can use the unique anchors to a timepoint to estimate differential TF binding, which is another analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degs_0_12 = pd.read_csv(\"/home/carlos/Desktop/manuscripts/notebooks/RNA/t0-t12.degs.tsv\", sep=\"\\t\")\n",
    "degs_0_60 = pd.read_csv(\"/home/carlos/Desktop/manuscripts/notebooks/RNA/t0-t60.degs.tsv\", sep=\"\\t\")\n",
    "degs_0_30 = pd.read_csv(\"/home/carlos/Desktop/manuscripts/notebooks/RNA/t0-t30.degs.tsv\", sep=\"\\t\")\n",
    "\n",
    "deseq_lrt = pd.read_csv(\"/home/carlos/Desktop/manuscripts/notebooks/RNA/all_deseq_lrt.tsv\", sep=\"\\t\")\n",
    "deseq_lrt.rename(columns={'gene_id': 'ensembl_gene_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gnn res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [f\"/home/carlos/Desktop/manuscripts/notebooks/gnn/t0_t12_results_{comp_now}.tsv\" for comp_now in [\"0_0\", \"1_0\", \"0_1\", \"1_1\"]]\n",
    "all_dfs = [pd.read_csv(df, sep=\"\\t\") for df in paths] \n",
    "all_regions = pd.concat(all_dfs) # This is the GNN evaluated regions\n",
    "all_regions = all_regions.iloc[:, :3]\n",
    "universe_3d_df = bioframe.overlap(all_regions, genes, how='inner')\n",
    "universe_3d_ids = list(universe_3d_df.gene_id_.dropna().unique())\n",
    "universe_3d_names = list(universe_3d_df.external_gene_name_.dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_labels = [\"comp1\", \"comp2\", \"comp3\", \"comp4\"]\n",
    "comp_files = [\"t0_t12_results_0_0\", \"t0_t12_results_0_1\", \"t0_t12_results_1_0\", \"t0_t12_results_1_1\"]\n",
    "\n",
    "filter_11 = False\n",
    "for label, comp in zip(comp_labels, comp_files):\n",
    "    regions = pd.read_csv(f\"/home/carlos/Desktop/manuscripts/notebooks/gnn/{comp}.tsv\", sep=\"\\t\")\n",
    "    filter_w_unibind = False\n",
    "\n",
    "    unibind_mapping = {\n",
    "        \"0_1\": \"0_1_vs_1_0\",\n",
    "        \"1_0\": \"1_0_vs_0_1\",\n",
    "        \"0_0\": \"0_0_vs_1_1\",\n",
    "        \"1_1\": \"1_1_vs_0_0\"\n",
    "    }\n",
    "\n",
    "    comp_name = comp[-3:]\n",
    "    if comp_name == \"1_1\" and filter_11:\n",
    "        regions = regions.loc[(regions[\"t0_q30-t12_q30\"] == 0) & (regions[\"t12_q30-t0_q30\"] == 0)]\n",
    "\n",
    "    if filter_w_unibind:\n",
    "        unibind_regions = pd.read_csv(f\"/home/carlos/Desktop/manuscripts/notebooks/unibind/gnn_res/gnn_{unibind_mapping[comp_name]}/extracted_regions_merged.bed\", sep=\"\\t\", header=None).iloc[:, :3]\n",
    "        unibind_regions.columns = ['chrom', 'start', 'end']\n",
    "        unibind_regions.start = unibind_regions.start.astype(int)\n",
    "        unibind_regions.end = unibind_regions.end.astype(int)\n",
    "        regions = bioframe.overlap(regions, unibind_regions, how='inner')\n",
    "\n",
    "\n",
    "    degs_0_12_degs, uni = overlapper(degs_0_12, regions, genes)\n",
    "    degs_0_30_degs, uni = overlapper(degs_0_30, regions, genes)\n",
    "    degs_0_60_degs, uni = overlapper(degs_0_60, regions, genes)\n",
    "\n",
    "    uni.to_csv(f\"gnn_enrichr_results_comp_wise/{label}_universe.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "    res_0_12 = enrichrrr(degs_0_12_degs, pathways, universe_3d_names)\n",
    "    res_0_30 = enrichrrr(degs_0_30_degs, pathways, universe_3d_names)\n",
    "    res_0_60 = enrichrrr(degs_0_60_degs, pathways, universe_3d_names)\n",
    "\n",
    "    comparison_dfs = merge_enrs_into_common_df_2([res_0_12, res_0_30, res_0_60], [\"0_12\", \"0_30\", \"0_60\"])\n",
    "\n",
    "    for res1, res2, res3, pathway in zip(res_0_12, res_0_30, res_0_60, pathways):\n",
    "        write_results(res1, f\"gnn_enrichr_results_comp_wise/{label}_{pathway}_0_12.tsv\")\n",
    "        write_results(res2, f\"gnn_enrichr_results_comp_wise/{label}_{pathway}_0_30.tsv\")\n",
    "        write_results(res3, f\"gnn_enrichr_results_comp_wise/{label}_{pathway}_0_60.tsv\")\n",
    "\n",
    "    database_names = [\"Gene Ontology\\nBiological Process\", \"MSigDB\\nHallmark\", \"NCI-Nature\\nPID\"]\n",
    "    \n",
    "    plot_count = 0\n",
    "    for i, (df, pathway) in enumerate(zip(comparison_dfs, pathways)):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "        if len(df) != 0:\n",
    "\n",
    "            df = df.loc[df.iloc[:,[0,1,2]].max(axis=1).sort_values(ascending=True).index]\n",
    "            df = df.iloc[-20:, :]\n",
    "            b = df.plot.barh(x='Term', ax=ax, color=['#A63446', \"#F5B841\", '#9DBBAE'])\n",
    "            b.axvline(x=-np.log10(0.05), color='black', linestyle='--', alpha=0.6, linewidth=3)\n",
    "            b.set_xlabel(f'-log$_{{10}}$(Adjusted P-value)', fontsize=20)\n",
    "\n",
    "            b.axvline(x=-np.log10(0.05), color='black', linestyle='--', alpha=.9, linewidth=3)\n",
    "\n",
    "            b.set_xlabel(f'-log$_{{10}}$ Adjusted P-value', fontsize=12)\n",
    "            b.set_ylabel(database_names[i], fontsize=20)\n",
    "\n",
    "            \n",
    "            # change font size of x and y ticks\n",
    "            b.tick_params(labelsize=8)\n",
    "            b.tick_params(axis='both', which='major', labelsize=10)\n",
    "            b.tick_params(axis='both', which='minor', labelsize=10)\n",
    "\n",
    "            db_name = database_names[i].replace(\"\\n\", \"_\")\n",
    "\n",
    "            #fig.suptitle(f\"{label}\", fontsize=30)\n",
    "            fig.set_tight_layout(True)\n",
    "            fig.savefig(f\"gnn_enrichr_results_comp_wise/{label}_{db_name}_pathways.svg\")\n",
    "            fig.savefig(f\"gnn_enrichr_results_comp_wise/{label}_{db_name}_pathways.png\", dpi=300, facecolor=\"white\", edgecolor='none')\n",
    "\n",
    "        fig.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp_files = [\"t0_t12_results_0_0\", \"t0_t12_results_0_1\", \"t0_t12_results_1_0\", \"t0_t12_results_1_1\"]\n",
    "\n",
    "# #regions = pd.concat([pd.read_csv(f\"/home/carlos/Desktop/manuscripts/notebooks/gnn/{comp}.tsv\", sep=\"\\t\") for comp in comp_files[:3]]) # combine comp1, comp2, comp3\n",
    "# #label = \"changed_regions\"\n",
    "# regions = pd.concat([pd.read_csv(f\"/home/carlos/Desktop/manuscripts/notebooks/gnn/{comp}.tsv\", sep=\"\\t\") for comp in comp_files[3:]])\n",
    "# label = \"unchanged_regions\"\n",
    "\n",
    "# degs_0_12_degs, _ = overlapper(degs_0_12, regions, genes)\n",
    "# degs_0_30_degs, _ = overlapper(degs_0_30, regions, genes)\n",
    "# degs_0_60_degs, _ = overlapper(degs_0_60, regions, genes)\n",
    "\n",
    "# res_0_12 = enrichrrr(degs_0_12_degs, pathways, universe_3d_names)\n",
    "# res_0_30 = enrichrrr(degs_0_30_degs, pathways, universe_3d_names)\n",
    "# res_0_60 = enrichrrr(degs_0_60_degs, pathways, universe_3d_names)\n",
    "\n",
    "# comparison_dfs = merge_enrs_into_common_df_2([res_0_12, res_0_30, res_0_60], [\"0_12\", \"0_30\", \"0_60\"])\n",
    "\n",
    "# for res1, res2, res3, pathway in zip(res_0_12, res_0_30, res_0_60, pathways):\n",
    "#     write_results(res1, f\"gnn_enrichr_results_all_vs_all/{label}_{pathway}_0_12.tsv\")\n",
    "#     write_results(res2, f\"gnn_enrichr_results_all_vs_all/{label}_{pathway}_0_30.tsv\")\n",
    "#     write_results(res3, f\"gnn_enrichr_results_all_vs_all/{label}_{pathway}_0_60.tsv\")\n",
    "\n",
    "# fig, ax = plt.subplots(3, 1, figsize=(10, 20))\n",
    "# plot_count = 0\n",
    "# for i, (df, pathway) in enumerate(zip(comparison_dfs, pathways)):\n",
    "\n",
    "#     if len(df) != 0:\n",
    "#         df = df.loc[df.iloc[:,[0,1,2]].mean(axis=1).sort_values(ascending=True).index]\n",
    "#         df = df.iloc[-20:, :]\n",
    "#         plot_count += 1\n",
    "#         b = df.plot.barh(x='Term', ax=ax[i], color=['#A63446', \"#F5B841\", '#9DBBAE'])\n",
    "\n",
    "#         b.axvline(x=-np.log10(0.05), color='black', linestyle='--', alpha=0.6, linewidth=3)\n",
    "#         b.set_xlabel(f'-log$_{{10}}$(Adjusted P-value)', fontsize=20)\n",
    "#         b.set_ylabel(f'{pathway} Term', fontsize=20)\n",
    "\n",
    "#     if plot_count != 0:\n",
    "#         fig.suptitle(f\"{label}\", fontsize=30)\n",
    "#         fig.set_tight_layout(True)\n",
    "#         fig.savefig(f\"gnn_enrichr_results_all_vs_all/{label}_pathways.svg\")\n",
    "#         fig.savefig(f\"gnn_enrichr_results_all_vs_all/{label}_pathways.png\", dpi=300, facecolor=\"white\", edgecolor='none')\n",
    "\n",
    "#         fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNN plot all vs all / Uniq Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_dfs_all_vs_all = []\n",
    "\n",
    "comp_files = [\"t0_t12_results_0_0\", \"t0_t12_results_0_1\", \"t0_t12_results_1_0\", \"t0_t12_results_1_1\"]\n",
    "\n",
    "regions = pd.concat([pd.read_csv(f\"/home/carlos/Desktop/manuscripts/notebooks/gnn/{comp}.tsv\", sep=\"\\t\") for comp in comp_files[:3]]) # combine comp1, comp2, comp3\n",
    "label = \"changed_regions\"\n",
    "\n",
    "\n",
    "degs_0_12_degs, _ = overlapper(degs_0_12, regions, genes)\n",
    "degs_0_30_degs, _ = overlapper(degs_0_30, regions, genes)\n",
    "degs_0_60_degs, _ = overlapper(degs_0_60, regions, genes)\n",
    "\n",
    "res_0_12 = enrichrrr(degs_0_12_degs, pathways, universe_3d_names)\n",
    "res_0_30 = enrichrrr(degs_0_30_degs, pathways, universe_3d_names)\n",
    "res_0_60 = enrichrrr(degs_0_60_degs, pathways, universe_3d_names)\n",
    "\n",
    "comparison_dfs = merge_enrs_into_common_df_2([res_0_12, res_0_30, res_0_60], [\"0_12\", \"0_30\", \"0_60\"])\n",
    "\n",
    "comparison_dfs_all_vs_all.append(comparison_dfs)\n",
    "\n",
    "regions = pd.concat([pd.read_csv(f\"/home/carlos/Desktop/manuscripts/notebooks/gnn/{comp}.tsv\", sep=\"\\t\") for comp in comp_files[3:]])\n",
    "label = \"unchanged_regions\"\n",
    "\n",
    "degs_0_12_degs, _ = overlapper(degs_0_12, regions, genes)\n",
    "degs_0_30_degs, _ = overlapper(degs_0_30, regions, genes)\n",
    "degs_0_60_degs, _ = overlapper(degs_0_60, regions, genes)\n",
    "\n",
    "res_0_12 = enrichrrr(degs_0_12_degs, pathways, universe_3d_names)\n",
    "res_0_30 = enrichrrr(degs_0_30_degs, pathways, universe_3d_names)\n",
    "res_0_60 = enrichrrr(degs_0_60_degs, pathways, universe_3d_names)\n",
    "\n",
    "comparison_dfs = merge_enrs_into_common_df_2([res_0_12, res_0_30, res_0_60], [\"0_12\", \"0_30\", \"0_60\"])\n",
    "comparison_dfs_all_vs_all.append(comparison_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_names = [\"Gene Ontology\\nBiological Process\", \"MSigDB\\nHallmark\", \"NCI-Nature\\nPID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Changed regions uniq terms\n",
    "\n",
    "\n",
    "for idx, (changed, notChanged) in enumerate(zip(comparison_dfs_all_vs_all[0], comparison_dfs_all_vs_all[1])):\n",
    "    fig , ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "    # find common terms \n",
    "    common_terms = list(set(changed.index).intersection(set(notChanged.index)))\n",
    "    # remove common terms from changed \n",
    "    df = changed.loc[~changed.index.isin(common_terms)]\n",
    "    df = df.loc[df.iloc[:,[0,1,2]].max(axis=1).sort_values(ascending=True).index]\n",
    "\n",
    "    if len(df) != 0:\n",
    "        df = df.iloc[-15:, :]\n",
    "        df.columns = ['12min', '30min', '60min', 'Term']\n",
    "        b = df.plot.barh(x='Term', ax=ax, color=['#A63446', \"#F5B841\", '#9DBBAE'])\n",
    "        b.axvline(x=-np.log10(0.05), color='black', linestyle='--', alpha=.9, linewidth=3)\n",
    "\n",
    "        b.set_xlabel(f'-log$_{{10}}$ Adjusted P-value', fontsize=12)\n",
    "        b.set_ylabel(database_names[idx], fontsize=20)\n",
    "\n",
    "        \n",
    "        # change font size of x and y ticks\n",
    "        b.tick_params(labelsize=8)\n",
    "        b.tick_params(axis='both', which='major', labelsize=10)\n",
    "        b.tick_params(axis='both', which='minor', labelsize=10)\n",
    "\n",
    "        db_name = database_names[idx].replace(\"\\n\", \"_\")\n",
    "        fig.set_tight_layout(True)\n",
    "        fig.savefig(f\"gnn_enrichr_results_all_vs_all_uc/{db_name}_pathways_changed_uniq_terms.svg\")\n",
    "        fig.savefig(f\"gnn_enrichr_results_all_vs_all_uc/{db_name}_pathways_changed_uniq_terms.png\", dpi=300, facecolor=\"white\", edgecolor='none')\n",
    "\n",
    "    fig.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Unchanged regions uniq terms\n",
    "\n",
    "for idx, (changed, notChanged) in enumerate(zip(comparison_dfs_all_vs_all[0], comparison_dfs_all_vs_all[1])):\n",
    "    fig , ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "    common_terms = list(set(changed.index).intersection(set(notChanged.index)))\n",
    "    # remove common terms from changed \n",
    "    df = notChanged.loc[~notChanged.index.isin(common_terms)]\n",
    "    if len(df) != 0:\n",
    "        df = df.loc[df.iloc[:,[0,1,2]].max(axis=1).sort_values(ascending=True).index]\n",
    "\n",
    "\n",
    "    if len(df) != 0:\n",
    "        df = df.iloc[-15:, :]\n",
    "        df.columns = ['12min', '30min', '60min', 'Term']\n",
    "        b = df.plot.barh(x='Term', ax=ax, color=['#A63446', \"#F5B841\", '#9DBBAE'])\n",
    "        b.axvline(x=-np.log10(0.05), color='black', linestyle='--', alpha=.9, linewidth=3)\n",
    "\n",
    "        b.set_xlabel(f'-log$_{{10}}$ Adjusted P-value', fontsize=12)\n",
    "        b.set_ylabel(database_names[idx], fontsize=20)\n",
    "\n",
    "        \n",
    "        # change font size of x and y ticks\n",
    "        b.tick_params(labelsize=8)\n",
    "        b.tick_params(axis='both', which='major', labelsize=10)\n",
    "        b.tick_params(axis='both', which='minor', labelsize=10)\n",
    "\n",
    "        db_name = database_names[idx].replace(\"\\n\", \"_\")\n",
    "        fig.set_tight_layout(True)\n",
    "        fig.savefig(f\"gnn_enrichr_results_all_vs_all_uc/{db_name}_pathways_unchanged_uniq_terms.svg\")\n",
    "        fig.savefig(f\"gnn_enrichr_results_all_vs_all_uc/{db_name}_pathways_unchanged_uniq_terms.png\", dpi=300, facecolor=\"white\", edgecolor='none')\n",
    "    \n",
    "    fig.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Changed regions common terms\n",
    "for idx, (changed, notChanged) in enumerate(zip(comparison_dfs_all_vs_all[0], comparison_dfs_all_vs_all[1])):\n",
    "    fig , ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "    common_terms = list(set(changed.index).intersection(set(notChanged.index)))\n",
    "\n",
    "    df = changed.loc[changed.index.isin(common_terms)]\n",
    "\n",
    "    if len(df) != 0:\n",
    "        df = df.loc[df.iloc[:,[0,1,2]].max(axis=1).sort_values(ascending=True).index]\n",
    "    \n",
    "    if len(df) != 0:\n",
    "        df = df.iloc[-15:, :]\n",
    "        df.columns = ['12min', '30min', '60min', 'Term']\n",
    "        b = df.plot.barh(x='Term', ax=ax, color=['#A63446', \"#F5B841\", '#9DBBAE'])\n",
    "        b.axvline(x=-np.log10(0.05), color='black', linestyle='--', alpha=.9, linewidth=3)\n",
    "\n",
    "        b.set_xlabel(f'-log$_{{10}}$ Adjusted P-value', fontsize=12)\n",
    "        b.set_ylabel(database_names[idx], fontsize=20)\n",
    "\n",
    "        \n",
    "        # change font size of x and y ticks\n",
    "        b.tick_params(labelsize=8)\n",
    "        b.tick_params(axis='both', which='major', labelsize=12)\n",
    "        b.tick_params(axis='both', which='minor', labelsize=12)\n",
    "        \n",
    "        db_name = database_names[idx].replace(\"\\n\", \"_\")\n",
    "\n",
    "        fig.set_tight_layout(True)\n",
    "        fig.savefig(f\"gnn_enrichr_results_all_vs_all_uc/{db_name}_pathways_changed_common_terms.svg\")\n",
    "        fig.savefig(f\"gnn_enrichr_results_all_vs_all_uc/{db_name}_pathways_changed_common_terms.png\", dpi=300, facecolor=\"white\", edgecolor='none')\n",
    "    \n",
    "    fig.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not Changed regions common terms\n",
    "for idx, (changed, notChanged) in enumerate(zip(comparison_dfs_all_vs_all[0], comparison_dfs_all_vs_all[1])):\n",
    "    fig , ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "    common_terms = list(set(changed.index).intersection(set(notChanged.index)))\n",
    "    # remove common terms from changed \n",
    "    df = notChanged.loc[notChanged.index.isin(common_terms)]\n",
    "\n",
    "    if len(df) != 0:\n",
    "        df = df.loc[df.iloc[:,[0,1,2]].max(axis=1).sort_values(ascending=True).index]\n",
    "    \n",
    "    if len(df) != 0:\n",
    "        df = df.iloc[-15:, :]\n",
    "        df.columns = ['12min', '30min', '60min', 'Term']\n",
    "        b = df.plot.barh(x='Term', ax=ax, color=['#A63446', \"#F5B841\", '#9DBBAE'])\n",
    "        b.axvline(x=-np.log10(0.05), color='black', linestyle='--', alpha=.9, linewidth=3)\n",
    "\n",
    "        b.set_xlabel(f'-log$_{{10}}$ Adjusted P-value', fontsize=12)\n",
    "        b.set_ylabel(database_names[idx], fontsize=20)\n",
    "\n",
    "        \n",
    "        # change font size of x and y ticks\n",
    "        b.tick_params(labelsize=8)\n",
    "        b.tick_params(axis='both', which='major', labelsize=12)\n",
    "        b.tick_params(axis='both', which='minor', labelsize=12)\n",
    "        db_name = database_names[idx].replace(\"\\n\", \"_\")\n",
    "\n",
    "        fig.set_tight_layout(True)\n",
    "        fig.savefig(f\"gnn_enrichr_results_all_vs_all_uc/{db_name}_pathways_unchanged_common_terms.svg\")\n",
    "        fig.savefig(f\"gnn_enrichr_results_all_vs_all_uc/{db_name}_pathways_unchanged_common_terms.png\", dpi=300, facecolor=\"white\", edgecolor='none')\n",
    "    \n",
    "    fig.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNN res, expression profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_geneID_to_name(geneID):\n",
    "    if geneID not in genes.gene_id.values:\n",
    "        return None\n",
    "    return genes.loc[genes.gene_id == geneID].external_gene_name.values[0]\n",
    "\n",
    "def map_txID_to_name(txID):\n",
    "    if txID not in genes.tx_id.values:\n",
    "        return None\n",
    "    return genes.loc[genes.tx_id == txID].external_gene_name.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['SU_100', 'SU_200', 'SU_300', 'SU_112', 'SU_212', 'SU_312', 'SU_130', 'SU_230', 'SU_330', 'SU_160', 'SU_260', 'SU_360']\n",
    "\n",
    "df = pd.read_csv(f\"/home/carlos/Desktop/projects/rna-seq/quant/SU_100/quant.sf\", sep=\"\\t\")\n",
    "df.Name = df.Name.apply(lambda x: x.split(\".\")[0])\n",
    "df = df.loc[df.Name.isin(genes.tx_id.values)]\n",
    "mapped_names = [map_txID_to_name(txID.split(\".\")[0]) for txID in df.Name.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = []\n",
    "\n",
    "for name in order:\n",
    "    df = pd.read_csv(f\"/home/carlos/Desktop/projects/rna-seq/quant/{name}/quant.sf\", sep=\"\\t\")\n",
    "    df.Name = df.Name.apply(lambda x: x.split(\".\")[0])\n",
    "    df = df.loc[df.Name.isin(genes.tx_id.values)]\n",
    "    df.rename(columns={'TPM': name}, inplace=True)\n",
    "    series.append(df[name])\n",
    "\n",
    "tcounts_df = pd.DataFrame(series).T\n",
    "\n",
    "tcounts_df['geneName'] = mapped_names\n",
    "\n",
    "for i, name in zip([0, 3, 6, 9], [\"Control\", \"12min\", \"30min\", \"60min\"]):\n",
    "    tcounts_df[name] = tcounts_df.iloc[:, i : i + 3].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which_Genes = [\n",
    "#     \"ATF2\", \"ATF3\", \"ATF4\", \n",
    "#     \"JUN\", \"JUNB\", \"JUND\",\n",
    "#     \"FOS\", \"FOSL1\", \"FOSL2\", \"FOSB\", \n",
    "#     \"MAF\", \"MAFB\",\n",
    "#     \"TP53\"]\n",
    "\n",
    "which_Genes = \"SURF1;POLH;GTF2B;ADCY6;BRF2;PRIM1;DGUOK;RNMT;SEC61A1;ZWINT;POLD1;RBX1;CDA;NELFE;RFC4\".split(\";\")\n",
    "plot_df = {\n",
    "    \"geneName\": [],\n",
    "    \"Mean\": [],\n",
    "    \"time\": []\n",
    "}\n",
    "\n",
    "for gene_oi in which_Genes:\n",
    "    for name in [\"Control\", \"12min\", \"30min\", \"60min\"]:\n",
    "        plot_df[\"geneName\"].append(gene_oi)\n",
    "        plot_df[\"Mean\"].append(tcounts_df.loc[tcounts_df.geneName == gene_oi, name].values[0])\n",
    "        plot_df[\"time\"].append(name)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10), ncols=len(which_Genes))\n",
    "plot_df = pd.DataFrame(plot_df)\n",
    "for i, gene_oi in enumerate(which_Genes):\n",
    "    sns.barplot(x=\"time\", y=\"Mean\", data=plot_df.loc[plot_df.geneName == gene_oi], ax=ax[i])\n",
    "    ax[i].set_title(gene_oi)\n",
    "    ax[i].set_ylabel(\"Mean TPM\")\n",
    "    ax[i].set_xlabel(\"Time\")\n",
    "    ax[i].set_xticklabels(ax[i].get_xticklabels(), rotation=45, horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anchor lost at JUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_files = [\"t0_t12_common_loops1\", \"t0_t12_common_loops2\", \"t0_t12_specific_loops1\", \"t0_t12_specific_loops2\"]\n",
    "\n",
    "anchor_universe = pd.concat([get_anchors(f\"/home/carlos/Desktop/manuscripts/notebooks/loops/loops_anchors_data/{comp}.tsv\") for comp in comp_files]).drop_duplicates().reset_index(drop=True)\n",
    "anchor_universe_df = bioframe.overlap(anchor_universe, genes, how='inner')\n",
    "anchor_universe_ids = list(anchor_universe_df.gene_id_.dropna().unique())\n",
    "anchor_universe_names = list(anchor_universe_df.external_gene_name_.dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = [\"common_loops1\", \"common_loops2\", \"specific_loops1\", \"specific_loops2\"]\n",
    "for label, comp in zip(labels, comp_files):\n",
    "    regions = get_anchors(f\"/home/carlos/Desktop/manuscripts/notebooks/loops/loops_anchors_data/{comp}.tsv\")\n",
    "    filter_w_unibind = False\n",
    "    if filter_w_unibind:\n",
    "        unibind_regions = pd.read_csv(f\"/home/carlos/Desktop/manuscripts/notebooks/unibind/anchor_res/t0_t12_2_1/extracted_regions_merged.bed\", sep=\"\\t\", header=None).iloc[:, :3]\n",
    "        unibind_regions.columns = ['chrom', 'start', 'end']\n",
    "        unibind_regions.start = unibind_regions.start.astype(int)\n",
    "        unibind_regions.end = unibind_regions.end.astype(int)\n",
    "        regions = bioframe.overlap(regions, unibind_regions, how='inner')\n",
    "\n",
    "    degs_0_12_degs = overlapper(degs_0_12, regions, genes)\n",
    "    degs_0_30_degs = overlapper(degs_0_30, regions, genes)\n",
    "    degs_0_60_degs = overlapper(degs_0_60, regions, genes)\n",
    "\n",
    "    res_0_12 = enrichrrr(degs_0_12_degs, pathways)#, anchor_universe_names)\n",
    "    res_0_30 = enrichrrr(degs_0_30_degs, pathways)#, anchor_universe_names)\n",
    "    res_0_60 = enrichrrr(degs_0_60_degs, pathways)#, anchor_universe_names)\n",
    "\n",
    "    comparison_dfs = merge_enrs_into_common_df_2([res_0_12, res_0_30, res_0_60], [\"0_12\", \"0_30\", \"0_60\"])\n",
    "\n",
    "    for res1, res2, res3, pathway in zip(res_0_12, res_0_30, res_0_60, pathways):\n",
    "        write_results(res1, f\"loops_enrichr_results/{label}_{pathway}_0_12.tsv\")\n",
    "        write_results(res2, f\"loops_enrichr_results/{label}_{pathway}_0_30.tsv\")\n",
    "        write_results(res3, f\"loops_enrichr_results/{label}_{pathway}_0_60.tsv\")\n",
    "\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(10, 20))\n",
    "    plot_count = 0\n",
    "    for i, (df, pathway) in enumerate(zip(comparison_dfs, pathways)):\n",
    "        print(len(df))\n",
    "        if len(df) != 0:\n",
    "            plot_count += 1\n",
    "            b = df.plot.barh(x='Term', ax=ax[i], color=['#A63446', \"#F5B841\", '#9DBBAE'])\n",
    "            b.axvline(x=-np.log10(0.05), color='black', linestyle='--', alpha=0.6, linewidth=3)\n",
    "            b.set_xlabel(f'-log$_{{10}}$(Adjusted P-value)', fontsize=20)\n",
    "            b.set_ylabel(f'{pathway} Term', fontsize=20)\n",
    "    if plot_count != 0:\n",
    "        fig.suptitle(f\"{label}\", fontsize=30)\n",
    "        fig.set_tight_layout(True)\n",
    "        fig.savefig(f\"loops_enrichr_results/{label}_pathways.svg\")\n",
    "        fig.savefig(f\"loops_enrichr_results/{label}_pathways.png\", dpi=300, facecolor=\"white\", edgecolor='none')\n",
    "\n",
    "    fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop anchors all vs all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"common_loops\", \"specific_loops1\", \"specific_loops2\"]\n",
    "\n",
    "for comp_name in [\"t0_t12\", \"t12_t30\", \"t30_t60\"]:#, \"t0_t60\", \"t0_t30\", \"t12_t60\"]:\n",
    "    comparison_dfs_all_vs_all_loops = []\n",
    "\n",
    "    regions = pd.concat([get_anchors(f\"/home/carlos/Desktop/manuscripts/notebooks/loops/loops_anchors_data_mc_True_AR_0/{comp_name}_{labels[i]}.tsv\") for i in [0,1]]).drop_duplicates().reset_index(drop=True)\n",
    "    degs_0_12_degs, _ = overlapper(degs_0_12, regions, genes)\n",
    "    degs_0_30_degs, _ = overlapper(degs_0_30, regions, genes)\n",
    "    degs_0_60_degs, _ = overlapper(degs_0_60, regions, genes)\n",
    "    res_0_12 = enrichrrr(degs_0_12_degs, pathways)\n",
    "    res_0_30 = enrichrrr(degs_0_30_degs, pathways)\n",
    "    res_0_60 = enrichrrr(degs_0_60_degs, pathways)\n",
    "    for res1, res2, res3, pathway in zip(res_0_12, res_0_30, res_0_60, pathways):\n",
    "        write_results(res1, f\"loops_enrichr_results/{pathway}_LOOP_{comp_name}_left_DEG_0_12.tsv\")\n",
    "        write_results(res2, f\"loops_enrichr_results/{pathway}_LOOP_{comp_name}_left_DEG_0_30.tsv\")\n",
    "        write_results(res3, f\"loops_enrichr_results/{pathway}_LOOP_{comp_name}_left_DEG_0_60.tsv\")\n",
    "\n",
    "    comparison_dfs = merge_enrs_into_common_df_2([res_0_12, res_0_30, res_0_60], [\"0_12\", \"0_30\", \"0_60\"])\n",
    "    comparison_dfs_all_vs_all_loops.append(comparison_dfs)\n",
    "\n",
    "    regions = pd.concat([get_anchors(f\"/home/carlos/Desktop/manuscripts/notebooks/loops/loops_anchors_data_mc_True_AR_0/{comp_name}_{labels[i]}.tsv\") for i in [0,2]]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    degs_0_12_degs, _ = overlapper(degs_0_12, regions, genes)\n",
    "    degs_0_30_degs, _ = overlapper(degs_0_30, regions, genes)\n",
    "    degs_0_60_degs, _ = overlapper(degs_0_60, regions, genes)\n",
    "\n",
    "    res_0_12 = enrichrrr(degs_0_12_degs, pathways)\n",
    "    res_0_30 = enrichrrr(degs_0_30_degs, pathways)\n",
    "    res_0_60 = enrichrrr(degs_0_60_degs, pathways)\n",
    "    for res1, res2, res3, pathway in zip(res_0_12, res_0_30, res_0_60, pathways):\n",
    "        write_results(res1, f\"loops_enrichr_results/{pathway}_LOOP_{comp_name}_right_DEG_0_12.tsv\")\n",
    "        write_results(res2, f\"loops_enrichr_results/{pathway}_LOOP_{comp_name}_right_DEG_0_30.tsv\")\n",
    "        write_results(res3, f\"loops_enrichr_results/{pathway}_LOOP_{comp_name}_right_DEG_0_60.tsv\")\n",
    "\n",
    "    comparison_dfs = merge_enrs_into_common_df_2([res_0_12, res_0_30, res_0_60], [\"0_12\", \"0_30\", \"0_60\"])\n",
    "    comparison_dfs_all_vs_all_loops.append(comparison_dfs)\n",
    "\n",
    "    # For example, in t0vs12, left is common and t0 specific, right is common and t12 specific\n",
    "\n",
    "    # Left regions uniq terms\n",
    "    database_names = [\"Gene Ontology\\nBiological Process\", \"MSigDB\\nHallmark\", \"NCI-Nature\\nPID\"]\n",
    "\n",
    "\n",
    "    for idx, (left, right) in enumerate(zip(comparison_dfs_all_vs_all_loops[0], comparison_dfs_all_vs_all_loops[1])):\n",
    "        fig , ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "        common_terms = list(set(left.index).intersection(set(right.index)))\n",
    "        df = left.loc[~left.index.isin(common_terms)]\n",
    "        df = df.loc[df.iloc[:,[0,1,2]].max(axis=1).sort_values(ascending=True).index]\n",
    "\n",
    "        if len(df) != 0:\n",
    "            df = df.iloc[-15:, :]\n",
    "            df.columns = ['12min', '30min', '60min', 'Term']\n",
    "            b = df.plot.barh(x='Term', ax=ax, color=['#A63446', \"#F5B841\", '#9DBBAE'])\n",
    "            b.axvline(x=-np.log10(0.05), color='black', linestyle='--', alpha=.9, linewidth=3)\n",
    "\n",
    "            b.set_xlabel(f'-log$_{{10}}$ Adjusted P-value', fontsize=12)\n",
    "            b.set_ylabel(database_names[idx], fontsize=20)\n",
    "\n",
    "            \n",
    "            # change font size of x and y ticks\n",
    "            b.tick_params(labelsize=8)\n",
    "            b.tick_params(axis='both', which='major', labelsize=10)\n",
    "            b.tick_params(axis='both', which='minor', labelsize=10)\n",
    "\n",
    "            db_name = database_names[idx].replace(\"\\n\", \"_\")\n",
    "            fig.set_tight_layout(True)\n",
    "            #fig.savefig(f\"loops_enrichr_results/{db_name}_pathways_left_uniq_terms_{comp_name}.svg\")\n",
    "            fig.savefig(f\"loops_enrichr_results/{db_name}_pathways_left_uniq_terms_{comp_name}.png\", dpi=300, facecolor=\"white\", edgecolor='none')\n",
    "\n",
    "        fig.clf()\n",
    "\n",
    "        # Right regions uniq terms\n",
    "\n",
    "    for idx, (left, right) in enumerate(zip(comparison_dfs_all_vs_all_loops[0], comparison_dfs_all_vs_all_loops[1])):\n",
    "        fig , ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "        common_terms = list(set(left.index).intersection(set(right.index)))\n",
    "        # remove common terms from changed \n",
    "        df = right.loc[~right.index.isin(common_terms)]\n",
    "        if len(df) != 0:\n",
    "            df = df.loc[df.iloc[:,[0,1,2]].max(axis=1).sort_values(ascending=True).index]\n",
    "\n",
    "\n",
    "        if len(df) != 0:\n",
    "            df = df.iloc[-15:, :]\n",
    "            df.columns = ['12min', '30min', '60min', 'Term']\n",
    "            b = df.plot.barh(x='Term', ax=ax, color=['#A63446', \"#F5B841\", '#9DBBAE'])\n",
    "            b.axvline(x=-np.log10(0.05), color='black', linestyle='--', alpha=.9, linewidth=3)\n",
    "\n",
    "            b.set_xlabel(f'-log$_{{10}}$ Adjusted P-value', fontsize=12)\n",
    "            b.set_ylabel(database_names[idx], fontsize=20)\n",
    "\n",
    "            \n",
    "            # change font size of x and y ticks\n",
    "            b.tick_params(labelsize=8)\n",
    "            b.tick_params(axis='both', which='major', labelsize=10)\n",
    "            b.tick_params(axis='both', which='minor', labelsize=10)\n",
    "\n",
    "            db_name = database_names[idx].replace(\"\\n\", \"_\")\n",
    "            fig.set_tight_layout(True)\n",
    "            #fig.savefig(f\"loops_enrichr_results/{db_name}_pathways_right_uniq_terms_{comp_name}.svg\")\n",
    "            fig.savefig(f\"loops_enrichr_results/{db_name}_pathways_right_uniq_terms_{comp_name}.png\", dpi=300, facecolor=\"white\", edgecolor='none')\n",
    "        \n",
    "        fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## draw graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_loops(loop_file_path, all_genes, annotate=\"external_gene_name\", flank=10_000):\n",
    "    loop_df = pd.read_csv(loop_file_path, sep=\"\\t\")\n",
    "    loop_df[\"indx\"] = loop_df.index\n",
    "    loop_df[f\"{annotate}\"] = \"\"\n",
    "\n",
    "    left_anchors = loop_df.iloc[:, [0,1,2,-1]].rename(columns={\"chrom1\": \"chrom\", \"start1\": \"start\", \"end1\": \"end\"})\n",
    "    left_anchors[\"indx\"] = left_anchors.index\n",
    "    left_anchors.start = left_anchors.start - flank\n",
    "    left_anchors.end = left_anchors.end + flank\n",
    "    right_anchors = loop_df.iloc[:, [3,4,5,-1]].rename(columns={\"chrom2\": \"chrom\", \"start2\": \"start\", \"end2\": \"end\"})\n",
    "    right_anchors[\"indx\"] = right_anchors.index\n",
    "    right_anchors.start = right_anchors.start - flank\n",
    "    right_anchors.end = right_anchors.end + flank\n",
    "    \n",
    "    strand_oriented_genes = all_genes.copy()\n",
    "    strand_oriented_genes['start'] = all_genes.apply(lambda x: x['start'] if x['strand'] == \"+\" else x['end'], axis=1)\n",
    "    strand_oriented_genes['end'] = strand_oriented_genes['start']\n",
    "    \n",
    "    left_anchors_ov = bioframe.overlap(left_anchors, strand_oriented_genes, how='left').dropna()\n",
    "    right_anchors_ov = bioframe.overlap(right_anchors, strand_oriented_genes, how='left').dropna()\n",
    "\n",
    "    annotate_ = f\"{annotate}_\"\n",
    "\n",
    "    for i,row in left_anchors_ov.iterrows():\n",
    "        loop_df.loc[loop_df.indx == row.indx, f\"{annotate}\"] += f\";{row[annotate_]}\"\n",
    "    for i,row in right_anchors_ov.iterrows():\n",
    "        loop_df.loc[loop_df.indx == row.indx, f\"{annotate}\"] += f\";{row[annotate_]}\"\n",
    "\n",
    "    loop_df.external_gene_name = loop_df.external_gene_name.apply(lambda x: x[1:] if x.startswith(\";\") else x)\n",
    "    loop_df.external_gene_name = loop_df.external_gene_name.apply(lambda x: x if x != \"\" else \"!!!\")\n",
    "\n",
    "    # drop indx column\n",
    "    loop_df.drop(columns=['indx'], inplace=True)\n",
    "\n",
    "    return loop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venn_df_annotated = annotate_loops(\"/home/carlos/Desktop/manuscripts/notebooks/loops/venn_df_Labeled.tsv\", genes, annotate=\"external_gene_name\", flank=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venn_df_annotated = venn_df_annotated.loc[venn_df_annotated.external_gene_name != \"!!!\"]\n",
    "deseq_lrt_sorted = deseq_lrt.sort_values(by='padj').external_gene_name.values\n",
    "\n",
    "prev = []\n",
    "all_common = []\n",
    "\n",
    "for i, gene_list in enumerate(venn_df_annotated.external_gene_name.values):\n",
    "    for gene in gene_list.split(\";\"):\n",
    "        if gene in deseq_lrt_sorted:\n",
    "            row = venn_df_annotated.iloc[i,:]\n",
    "            padj = deseq_lrt.loc[deseq_lrt.external_gene_name == gene].padj.values[0]\n",
    "            prev.append((gene, padj, row['label'], (row.chrom1, row.start1, row.end1, row.chrom2, row.start2, row.end2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe with prev\n",
    "prev_df = {\n",
    "    \"gene\": [],\n",
    "    \"padj\": [],\n",
    "    \"label\": [],\n",
    "    \"chrom1\": [],\n",
    "    \"start1\": [],\n",
    "    \"end1\": [],\n",
    "    \"chrom2\": [],\n",
    "    \"start2\": [],\n",
    "    \"end2\": []\n",
    "}\n",
    "\n",
    "for gene, padj, label, (chrom1, start1, end1, chrom2, start2, end2) in prev:\n",
    "    prev_df[\"gene\"].append(gene)\n",
    "    prev_df[\"padj\"].append(padj)\n",
    "    prev_df[\"label\"].append(label)\n",
    "    prev_df[\"chrom1\"].append(chrom1)\n",
    "    prev_df[\"start1\"].append(start1)\n",
    "    prev_df[\"end1\"].append(end1)\n",
    "    prev_df[\"chrom2\"].append(chrom2)\n",
    "    prev_df[\"start2\"].append(start2)\n",
    "    prev_df[\"end2\"].append(end2)\n",
    "\n",
    "prev_df = pd.DataFrame(prev_df)\n",
    "prev_df.sort_values(by= [\"chrom1\", \"start1\", \"start2\"], inplace=True)\n",
    "\n",
    "filter_coords_df = prev_df.loc[prev_df.label == '1,2,3,4 intersection']\n",
    "\n",
    "for i,row in filter_coords_df.iterrows():\n",
    "    chrom1, start1, end1, chrom2, start2, end2 = row.chrom1, row.start1, row.end1, row.chrom2, row.start2, row.end2\n",
    "    prev_df = prev_df.loc[~((prev_df.chrom1 == chrom1) & (prev_df.start1 == start1) & (prev_df.end1 == end1) & (prev_df.chrom2 == chrom2) & (prev_df.start2 == start2) & (prev_df.end2 == end2))]\n",
    "\n",
    "prev_df.sort_values(by= \"padj\", inplace=True)\n",
    "\n",
    "topN = 20\n",
    "\n",
    "topGenes = prev_df.gene.unique()[:topN]\n",
    "\n",
    "prev_df = prev_df.loc[prev_df.gene.isin(topGenes)]\n",
    "prev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_label(gene_df):\n",
    "    l = [i.split(\" \")[0].split(\",\") for i in gene_df.label.to_list()]\n",
    "    return [(idx, [int(i) for i in j]) for idx,j in enumerate(l)]\n",
    "\n",
    "def is_gene_in_coords(coords_df, all_genes):\n",
    "    strand_oriented_genes = all_genes.copy()\n",
    "\n",
    "    strand_oriented_genes['start'] = all_genes.apply(lambda x: x['start'] if x['strand'] == \"+\" else x['end'], axis=1)\n",
    "    strand_oriented_genes['end'] = strand_oriented_genes['start']\n",
    "\n",
    "    return bioframe.overlap(coords_df, strand_oriented_genes, how='left').dropna()\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "graphs = []\n",
    "\n",
    "for i, gene_df in prev_df.groupby('gene').__iter__():\n",
    "    anchors = {\n",
    "        \"coords\": [],\n",
    "        \"timepoints\": [],\n",
    "        \"pairs\": [],\n",
    "    }\n",
    "\n",
    "    for r_idx, row in gene_df.iterrows():\n",
    "        chromName = row.chrom1\n",
    "        geneName = row.gene\n",
    "        anchor1_coord = row.start1\n",
    "        anchor2_coord = row.start2\n",
    "        anchors[\"coords\"].append(anchor1_coord)\n",
    "        timepoint = [int(tp) for tp in row.label.split(\" \")[0].split(\",\")]\n",
    "        anchors[\"timepoints\"].append(timepoint)\n",
    "        anchors[\"pairs\"].append(anchor2_coord)\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    for coord, timepoint, pair in zip(anchors[\"coords\"], anchors[\"timepoints\"], anchors[\"pairs\"]):\n",
    "        G.add_edge(coord, pair, timepoint=timepoint)\n",
    "\n",
    "    tolerance = 10_000\n",
    "\n",
    "    for node in G.nodes:\n",
    "        coord_df = pd.DataFrame({\"chrom\":[chromName], \"start\": [node-tolerance], \"end\": [node+(tolerance*2)]})\n",
    "        coord_df.start = coord_df.start.astype(int)\n",
    "        coord_df.end = coord_df.end.astype(int)\n",
    "        ov = is_gene_in_coords(coord_df, genes)\n",
    "\n",
    "        if len(ov) != 0:\n",
    "            if geneName in ov.external_gene_name_.values:\n",
    "                G.nodes[node]['color'] = \"red\"\n",
    "            else:\n",
    "                G.nodes[node]['color'] = \"blue\"\n",
    "        else:\n",
    "            G.nodes[node]['color'] = \"blue\"\n",
    "\n",
    "    import itertools\n",
    "\n",
    "    nodes_to_remove = []\n",
    "\n",
    "    for node1, node2 in itertools.combinations(G.nodes, 2):\n",
    "\n",
    "        # If the absolute difference between the node coordinates is less than or equal to the tolerance\n",
    "        if abs(node1 - node2) <= tolerance:\n",
    "            # Merge the nodes by adding the edges of the second node to the first node\n",
    "            for neighbor, data in G[node2].items():\n",
    "                if G.has_edge(node1, neighbor):\n",
    "                    # If the first node already has an edge to the neighbor, add the timepoints of the second node's edge to the first node's edge\n",
    "                    G[node1][neighbor]['timepoint'] += data['timepoint']\n",
    "                else:\n",
    "                    # Otherwise, add the edge from the second node to the first node\n",
    "                    G.add_edge(node1, neighbor, timepoint=data['timepoint'])\n",
    "            \n",
    "            # Add the second node to the list of nodes to be removed\n",
    "            nodes_to_remove.append(node2)\n",
    "\n",
    "    # Remove the nodes from the graph\n",
    "    for node in nodes_to_remove:\n",
    "        if node in G:\n",
    "            G.remove_node(node)\n",
    "\n",
    "    graphs.append((geneName, G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw graph\n",
    "for geneName, G in graphs:\n",
    "    edges = G.edges(data=True)\n",
    "    timepoint_data = [set(data['timepoint']) for u, v, data in edges]\n",
    "    if [set([1,2,3,4])] == timepoint_data:\n",
    "        continue\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    pos = nx.spring_layout(G, k=0.5, iterations=100)\n",
    "\n",
    "    node_colors = [G.nodes[node]['color'] for node in G.nodes]\n",
    "\n",
    "    nx.draw(G, pos, ax=ax, node_size=1000, node_color=node_colors, edge_color='black', width=1, font_size=18, font_color='red')\n",
    "    nx.draw_networkx_labels(G, pos, font_size=20, font_color='green')\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=nx.get_edge_attributes(G, 'timepoint'), font_size=18, font_color='red')\n",
    "    fig.savefig(f\"/home/carlos/Desktop/manuscripts/notebooks/loops/graphs/{geneName}_graph.png\", dpi=300, facecolor=\"white\", edgecolor='none')\n",
    "    fig.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8), ncols=2, nrows=1, sharey=\"row\",\n",
    " gridspec_kw={\"wspace\": 0.1, 'width_ratios': [3, 4]})\n",
    "\n",
    "topN_now = 20\n",
    "\n",
    "deseq_lrt_intersect_topN = deseq_lrt.loc[deseq_lrt.external_gene_name.isin(topGenes)].sort_values(by='padj').head(topN_now)\n",
    "\n",
    "plot_dict_FC = {\n",
    "    \"geneName\": [],\n",
    "    \"Fold Change\": [],\n",
    "    \"Time Point\": []\n",
    "}\n",
    "\n",
    "fc_12 = degs_0_12.loc[degs_0_12.ensembl_gene_id.isin(deseq_lrt_intersect_topN.ensembl_gene_id.values)]\n",
    "fc_30 = degs_0_30.loc[degs_0_30.ensembl_gene_id.isin(deseq_lrt_intersect_topN.ensembl_gene_id.values)]\n",
    "fc_60 = degs_0_60.loc[degs_0_60.ensembl_gene_id.isin(deseq_lrt_intersect_topN.ensembl_gene_id.values)]\n",
    "\n",
    "plot_dict_padj = {\n",
    "    \"geneName\": [],\n",
    "    \"padj\": [],\n",
    "}\n",
    "\n",
    "for gene in deseq_lrt_intersect_topN.external_gene_name.values:\n",
    "    \n",
    "    plot_dict_FC[\"geneName\"].append(gene)\n",
    "    plot_dict_FC[\"geneName\"].append(gene)\n",
    "    plot_dict_FC[\"geneName\"].append(gene)\n",
    "\n",
    "\n",
    "    if gene not in fc_12.external_gene_name.values:\n",
    "        plot_dict_FC[\"Fold Change\"].append(0)\n",
    "    else:\n",
    "        plot_dict_FC[\"Fold Change\"].append(fc_12.loc[fc_12.external_gene_name == gene].log2FoldChange.values[0])\n",
    "    plot_dict_FC[\"Time Point\"].append(\"12min\")\n",
    "\n",
    "    if gene not in fc_30.external_gene_name.values:\n",
    "        plot_dict_FC[\"Fold Change\"].append(0)\n",
    "    else:\n",
    "        plot_dict_FC[\"Fold Change\"].append(fc_30.loc[fc_30.external_gene_name == gene].log2FoldChange.values[0])\n",
    "    plot_dict_FC[\"Time Point\"].append(\"30min\")\n",
    "\n",
    "    if gene not in fc_60.external_gene_name.values:\n",
    "        plot_dict_FC[\"Fold Change\"].append(0)\n",
    "    else:\n",
    "        plot_dict_FC[\"Fold Change\"].append(fc_60.loc[fc_60.external_gene_name == gene].log2FoldChange.values[0])\n",
    "    plot_dict_FC[\"Time Point\"].append(\"60min\")\n",
    "\n",
    "    plot_dict_padj[\"geneName\"].append(gene)\n",
    "    padj = deseq_lrt_intersect_topN.loc[deseq_lrt_intersect_topN.external_gene_name == gene].padj.values[0]\n",
    "    minus_log10_padj = -np.log10(padj)\n",
    "    if minus_log10_padj == np.inf:\n",
    "        minus_log10_padj = 308\n",
    "    plot_dict_padj[\"padj\"].append(minus_log10_padj)\n",
    "\n",
    "\n",
    "plot_df_FC = pd.DataFrame(plot_dict_FC)\n",
    "plot_df_padj = pd.DataFrame(plot_dict_padj)\n",
    "\n",
    "b1 = sns.barplot(x=\"padj\", y=\"geneName\", data=plot_df_padj, ax=ax[0], palette=[\"#465775\"])\n",
    "b1.set_xticklabels(ax[0].get_xticklabels(), rotation=45, horizontalalignment='right', fontsize=20)\n",
    "b1.set_ylabel(\"Top 20 Genes\", fontsize=12)\n",
    "b1.set_xlabel(f\"-log$_{{10}}$ Adjusted p-value\", fontsize=12)\n",
    "b1.tick_params(axis='both', which='major', labelsize=12)\n",
    "b1.tick_params(axis='both', which='minor', labelsize=12)\n",
    "\n",
    "b2 = sns.barplot(x=\"Fold Change\", y=\"geneName\", hue=\"Time Point\", data=plot_df_FC, ax=ax[1], palette=['#A63446', \"#F5B841\", '#9DBBAE'])\n",
    "b2.set_xticklabels(ax[1].get_xticklabels(), rotation=45, horizontalalignment='right', fontsize=20)\n",
    "b2.set_ylabel(\"padj\")\n",
    "b2.set_xlabel(\"Gene Name\")\n",
    "b2.axvline(x=0, color='black', linestyle='-', lw=0.5)\n",
    "b2.tick_params(axis='both', which='major', labelsize=12)\n",
    "b2.tick_params(axis='both', which='minor', labelsize=12)\n",
    "b2.set_xlabel(f\"log$_{{2}}$ Fold Change\", fontsize=12) \n",
    "\n",
    "# Calculate the number of bars\n",
    "num_bars = len(plot_df_FC['geneName'].unique())\n",
    "# Calculate the y-tick locations\n",
    "y_ticks = np.arange(num_bars)\n",
    "# Set the y-ticks\n",
    "ax[0].set_yticks(y_ticks)\n",
    "ax[1].set_yticks(y_ticks)\n",
    "# Get the unique gene names\n",
    "gene_names = plot_df_FC['geneName'].unique()\n",
    "# Set the y-tick labels back to the gene names\n",
    "ax[0].set_yticklabels(gene_names)\n",
    "ax[1].set_yticklabels(gene_names)\n",
    "# Add grid lines at halfway points\n",
    "ax[0].set_yticks(y_ticks + 0.5, minor=True)\n",
    "ax[1].set_yticks(y_ticks + 0.5, minor=True)\n",
    "ax[0].grid(axis='y', which='minor', linestyle='-', alpha=1, lw=.5, color=\"black\")\n",
    "ax[1].grid(axis='y', which='minor', linestyle='-', alpha=1, lw=.5, color=\"black\")\n",
    "ax[1].set_yticklabels(gene_names)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"/home/carlos/Desktop/manuscripts/notebooks/loops/graphs/FC_padj.png\", dpi=300, facecolor=\"white\", edgecolor='none')\n",
    "fig.savefig(f\"/home/carlos/Desktop/manuscripts/notebooks/loops/graphs/FC_padj.svg\", facecolor=\"white\", edgecolor='none')\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = genes.loc[genes.external_gene_name == \"JUN\"]\n",
    "chromName = row.chrom.values[0]\n",
    "start = row.start.values[0]\n",
    "end = row.end.values[0]\n",
    "strand = row.strand.values[0]\n",
    "\n",
    "flank_now = 5000\n",
    "\n",
    "if strand == \"+\":\n",
    "    print(f\"{chromName}:{start // 10_000 * 10_000}\")\n",
    "    print(f\"{chromName}:{start - flank_now}-{start + flank_now}\")\n",
    "else:\n",
    "    print(f\"{chromName}:{end // 10_000 * 10_000}\") \n",
    "    print(f\"{chromName}:{end - flank_now}-{end + flank_now}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get strength changes of loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cooltools\n",
    "import os\n",
    "resolution = 10_000\n",
    "\n",
    "samples = [\"t0\", \"t12\", \"t30\", \"t60\"]\n",
    "clrs_ = [\n",
    "    cooler.Cooler(\n",
    "        f\"/home/carlos/Desktop/manuscripts/notebooks/matrices/{sample}_q30.mcool::resolutions/10000\"\n",
    "    )\n",
    "    for sample in samples\n",
    "]\n",
    "\n",
    "hg38_chromsizes = bioframe.fetch_chromsizes(\"hg38\")\n",
    "hg38_cens = bioframe.fetch_centromeres(\"hg38\")\n",
    "hg38_arms = bioframe.make_chromarms(hg38_chromsizes, hg38_cens)\n",
    "hg38_arms = hg38_arms.set_index(\"chrom\").loc[clrs_[0].chromnames].reset_index()\n",
    "\n",
    "if not os.path.exists(\"/home/carlos/Desktop/manuscripts/notebooks/loops/expected_t0.10000.csv\"):\n",
    "    # intra-arm expected\n",
    "    expected_ = [\n",
    "        cooltools.expected_cis(\n",
    "            clr,\n",
    "            view_df=hg38_arms,\n",
    "            nproc=nproc,\n",
    "        )\n",
    "        for clr in clrs_\n",
    "    ]\n",
    "\n",
    "    for sample, exp_df in zip(samples, expected_):\n",
    "        exp_df.to_csv(f\"expected_{sample}.10000.csv\", index=False)\n",
    "else:\n",
    "    expected_ = [\n",
    "        pd.read_csv(f\"/home/carlos/Desktop/manuscripts/notebooks/loops/expected_{sample}.10000.csv\")\n",
    "        for sample in samples\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_mtx_dict = {}\n",
    "\n",
    "for geneName, G in graphs:\n",
    "    edges = G.edges(data=True)\n",
    "    timepoint_data = [list(data['timepoint']) for u, v, data in edges]\n",
    "    timepoint_index = [[i-1 for i in tp_list] for tp_list in timepoint_data]\n",
    "\n",
    "    heatmap_mtx = np.zeros((len(timepoint_index), 4))\n",
    "\n",
    "    for idx, tp_list in enumerate(timepoint_index):\n",
    "        for tp in tp_list:\n",
    "            heatmap_mtx[idx, tp] = 1\n",
    "    if geneName == \"JUN\":\n",
    "        print(heatmap_mtx)\n",
    "    heatmap_mtx_dict[geneName] = heatmap_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def P2M(data):\n",
    "#     total = np.nansum(data)\n",
    "#     center_idx = data.shape[0] // 2\n",
    "#     center_score = data[center_idx, center_idx]\n",
    "#     return center_score / ((total - center_score) / (data.size - 1))\n",
    "\n",
    "# def central_score(data, n=3):\n",
    "#     c = data.shape[0] // 2\n",
    "#     return np.nanmean(data[c - n // 2 : c + n // 2 + 1, c - n // 2 : c + n // 2 + 1])\n",
    "    \n",
    "    \n",
    "# apa_flank = 100_000\n",
    "\n",
    "# gene_name_loopDF_ = {}\n",
    "# for geneName, G in graphs:\n",
    "\n",
    "#     edges = G.edges(data=True)\n",
    "#     timepoint_data = [set(data['timepoint']) for u, v, data in edges]\n",
    "#     if [set([1,2,3,4])] == timepoint_data:\n",
    "#         continue\n",
    "#     filter_ = venn_df_annotated.external_gene_name.apply(lambda x: True if sum([1 for gene in x.split(\";\") if gene == geneName]) > 0 else False)\n",
    "#     loop_df = venn_df_annotated.loc[filter_]\n",
    "#     loop_df = loop_df.sort_values(by=['start1', 'start2', 'label']).reset_index(drop=True)\n",
    "    \n",
    "\n",
    "    \n",
    "#     i1_i2 = [[] for i in range(len(loop_df))]\n",
    "\n",
    "#     for i1, row1 in loop_df.iterrows():\n",
    "#         for i2, row2 in loop_df.iterrows():\n",
    "#             if i1 != i2:\n",
    "#                 loop_1_start1 = row1.start1\n",
    "#                 loop_1_start2 = row1.start2\n",
    "\n",
    "#                 loop_1_range1 = range(loop_1_start1 - 10_000, loop_1_start1 + 20_000)\n",
    "#                 loop_1_range2 = range(loop_1_start2 - 10_000, loop_1_start2 + 20_000)\n",
    "\n",
    "#                 loop_2_start1 = row2.start1\n",
    "#                 loop_2_start2 = row2.start2\n",
    "\n",
    "#                 if loop_2_start1 in loop_1_range1 and loop_2_start2 in loop_1_range2:\n",
    "#                     if loop_1_start1 == loop_2_start1 and loop_1_start2 == loop_2_start2:\n",
    "#                         continue\n",
    "#                     i1_i2[i1].append(i2)\n",
    "\n",
    "#     loop_df['common_pairs'] = i1_i2\n",
    "\n",
    "#     sample_idx_dict = {\n",
    "#         0: \"t0\",\n",
    "#         1: \"t12\",\n",
    "#         2: \"t30\",\n",
    "#         3: \"t60\"\n",
    "#     }\n",
    "\n",
    "#     for sample_idx, (clr, expected) in enumerate(zip(clrs_, expected_)): # for each sample\n",
    "#         mtx_ = cooltools.pileup(clr, loop_df, view_df=hg38_arms, expected_df=expected, flank=apa_flank, nproc=1)\n",
    "#         scores = [P2M(mtx_[:,:,i]) for i in range(mtx_.shape[2])]\n",
    "#         loop_df[f\"score_{sample_idx_dict[sample_idx]}\"] = scores\n",
    "\n",
    "    \n",
    "#     loop_df.drop_duplicates(subset=[\"score_t0\", \"score_t12\", \"score_t30\", \"score_t60\"], inplace=True)\n",
    "    \n",
    "#     if len(loop_df) != len(edges):\n",
    "#         print(geneName)\n",
    "#         print(edges)\n",
    "#         print(loop_df)\n",
    "    \n",
    "#     loop_df.to_csv(f\"/home/carlos/Desktop/manuscripts/notebooks/loops/graphs/{geneName}_loop_df.tsv\", sep=\"\\t\", index=False)\n",
    "    \n",
    "\n",
    "#     graph_loops = {\n",
    "#         \"chrom1\": [],\n",
    "#         \"start1\": [],\n",
    "#         \"end1\": [],\n",
    "#         \"chrom2\": [],\n",
    "#         \"start2\": [],\n",
    "#         \"end2\": [],\n",
    "#     }\n",
    "\n",
    "#     chromName = loop_df.chrom1.values[0]\n",
    "\n",
    "#     for edge in edges:\n",
    "#         n1, n2 = edge[0], edge[1]\n",
    "\n",
    "#         if n1 > n2:\n",
    "#             n1, n2 = n2, n1\n",
    "            \n",
    "#         graph_loops[\"chrom1\"].append(chromName)\n",
    "#         graph_loops[\"start1\"].append(n1)\n",
    "#         graph_loops[\"end1\"].append(n1+10_000)\n",
    "#         graph_loops[\"chrom2\"].append(chromName)\n",
    "#         graph_loops[\"start2\"].append(n2)\n",
    "#         graph_loops[\"end2\"].append(n2+10_000)\n",
    "\n",
    "#         sample_idx_dict = {\n",
    "#         0: \"t0\",\n",
    "#         1: \"t12\",\n",
    "#         2: \"t30\",\n",
    "#         3: \"t60\"\n",
    "#     }\n",
    "\n",
    "    \n",
    "\n",
    "#     graph_loops = pd.DataFrame(graph_loops)\n",
    "\n",
    "#     for sample_idx, (clr, expected) in enumerate(zip(clrs_, expected_)): # for each sample\n",
    "#         mtx_ = cooltools.pileup(clr, graph_loops, view_df=hg38_arms, expected_df=expected, flank=apa_flank, nproc=1)\n",
    "#         scores = [P2M(mtx_[:,:,i]) for i in range(mtx_.shape[2])]\n",
    "#         graph_loops[f\"score_{sample_idx_dict[sample_idx]}\"] = scores\n",
    "    \n",
    "#     graph_loops.to_csv(f\"/home/carlos/Desktop/manuscripts/notebooks/loops/graphs/{geneName}_graph_df.tsv\", sep=\"\\t\", index=False)\n",
    "    \n",
    "#     gene_name_loopDF_[geneName] = graph_loops.copy()\n",
    "\n",
    "# genes_order = deseq_lrt_intersect_topN.external_gene_name.to_list()\n",
    "# # sort gene_name_loopDF_ by genes_order, and get rid of duplicates\n",
    "# gene_name_loopDF_ = {geneName: gene_name_loopDF_[geneName] for geneName in genes_order}\n",
    "\n",
    "# heatmap_mtx_dict = {}\n",
    "\n",
    "# for k,v in gene_name_loopDF_.items():\n",
    "#     heatmap_mtx = v.iloc[:, -4:].values\n",
    "\n",
    "#     #heatmap_mtx_scaled = (heatmap_mtx - heatmap_mtx.min()) / (heatmap_mtx.max() - heatmap_mtx.min())\n",
    "#     #heatmap_mtx_scaled = heatmap_mtx / heatmap_mtx.max() \n",
    "    \n",
    "#     #divide each to its max\n",
    "#     heatmap_mtx_scaled = np.zeros_like(heatmap_mtx)\n",
    "#     for i in range(heatmap_mtx.shape[0]):\n",
    "#         for j in range(heatmap_mtx.shape[1]):\n",
    "#             heatmap_mtx_scaled[i,j] = heatmap_mtx[i,j] / heatmap_mtx[i,:].max()\n",
    "    \n",
    "#     heatmap_mtx_dict[k] = heatmap_mtx_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re order heatmap_mtx_dict\n",
    "heatmap_mtx_dict = {k: heatmap_mtx_dict[k] for k in topGenes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "#cmp = LinearSegmentedColormap.from_list(\"custom_cmp\", [\"#A63446\", \"white\", \"#14213D\"], N=256)\n",
    "cmp = LinearSegmentedColormap.from_list(\"custom_cmp\", [\"white\", \"#465775\"], N=256)\n",
    "\n",
    "fig2, ax_hm = plt.subplots(figsize=(4, 8), ncols=1, nrows=topN, gridspec_kw={\"hspace\": 0}, sharex=True)\n",
    "\n",
    "for idx, (k,v) in enumerate(heatmap_mtx_dict.items()):\n",
    "    s = sns.heatmap(v, ax=ax_hm[idx], cmap=cmp, cbar=False, yticklabels=False, xticklabels=False)\n",
    "\n",
    "\n",
    "fig2.savefig(f\"/home/carlos/Desktop/manuscripts/notebooks/loops/graphs/heatmap.png\", dpi=300, facecolor=\"white\", edgecolor='none')\n",
    "fig2.savefig(f\"/home/carlos/Desktop/manuscripts/notebooks/loops/graphs/heatmap.svg\", facecolor=\"white\", edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_colorbar(vmin_value, vmax_value, cmap, ax=None, orientation='vertical'):\n",
    "\n",
    "#     cbar = plt.colorbar(plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin_value, vmax=vmax_value)),\n",
    "#                         orientation=orientation, cax=ax,)\n",
    "\n",
    "#     if orientation == 'horizontal':\n",
    "#         ax.set_yticks([])\n",
    "#         ax.set_xticks([vmin_value, vmax_value])\n",
    "#         cbar.ax.tick_params(labelsize=16)\n",
    "\n",
    "#     elif orientation == 'vertical':\n",
    "#         ax.set_xticks([])\n",
    "#         ax.set_yticks([vmin_value, vmax_value])\n",
    "#         cbar.ax.tick_params(labelsize=16)\n",
    "\n",
    "#     plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(8, 1))\n",
    "# create_colorbar(0.25, 1, cmp, orientation='horizontal', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TADs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tads_df = pd.read_csv(\"/home/carlos/Desktop/manuscripts/notebooks/boundaries/boundary_switch_1_True.tsv\", sep=\"\\t\")\n",
    "clr = cooler.Cooler(\"/home/carlos/Desktop/manuscripts/notebooks/matrices/t0_q30.mcool::resolutions/10000\")\n",
    "bins = clr.bins()[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_set_idx = list(set(tads_df.idx1.tolist() + tads_df.idx2.tolist()))\n",
    "super_set_bins = bins.iloc[super_set_idx,:].reset_index(drop=True).dropna(subset=['weight'])\n",
    "\n",
    "boundary_flanks = 10_000\n",
    "\n",
    "super_set_bins['start'] -= boundary_flanks\n",
    "super_set_bins['end'] += boundary_flanks\n",
    "boundary_universe = bioframe.overlap(super_set_bins, genes, how='inner')\n",
    "boundary_universe_names = list(boundary_universe.external_gene_name_.dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_ = []\n",
    "for case in ['Preserved', 'Lost']:\n",
    "    for sample1 in [\"Control\", \"12min\", \"30min\", \"60min\"]:\n",
    "        for sample2 in [\"Control\", \"12min\", \"30min\", \"60min\"]:\n",
    "            if sample1 != sample2:\n",
    "                if case == 'Preserved':\n",
    "                    curr_df = tads_df.loc[(tads_df['sample1'] == sample1) & (tads_df['sample2'] == sample2) & (tads_df['case'].isin([\"Shifted\", \"Preserved\"]))]\n",
    "                    curr_df['bs_change'] = curr_df['bs2'].values - curr_df['bs1'].values\n",
    "                    curr_df['bs_change_levels'] = pd.qcut(curr_df.bs_change, 4, labels=[\"1\", \"2\", \"3\", \"4\"])\n",
    "\n",
    "                    print(f\"{case}_{sample1}_{sample2}\")\n",
    "                    print(curr_df.groupby('bs_change_levels')['bs_change'].mean())\n",
    "\n",
    "                    curr_df = curr_df.loc[curr_df['bs_change_levels'].isin([\"4\"])]\n",
    "\n",
    "                    idx_.append(curr_df.idx1.to_list())\n",
    "                else:\n",
    "                    curr_df = tads_df.loc[(tads_df['sample1'] == sample1) & (tads_df['sample2'] == sample2) & (tads_df['case'] == \"Lost\")]\n",
    "                    idx_.append(curr_df.idx1.to_list())\n",
    "\n",
    "\n",
    "                regions = bins.iloc[curr_df.idx1.to_list(), :].reset_index(drop=True)\n",
    "                regions['start'] -= boundary_flanks\n",
    "                regions['end'] += boundary_flanks\n",
    "\n",
    "                degs_0_12_degs = overlapper(degs_0_12, regions, genes)\n",
    "                degs_0_60_degs = overlapper(degs_0_60, regions, genes)\n",
    "\n",
    "                res_0_12 = enrichrrr(degs_0_12_degs, pathways)#, boundary_universe_names)\n",
    "                res_0_60 = enrichrrr(degs_0_60_degs, pathways)#, boundary_universe_names)\n",
    "\n",
    "                comparison_dfs = merge_enrs_into_common_df(res_0_12, res_0_30)\n",
    "\n",
    "                for res1, res2, pathway in zip(res_0_12, res_0_60, pathways):\n",
    "                    df1= res1.results.sort_values('Adjusted P-value')\n",
    "                    df2 = res2.results.sort_values('Adjusted P-value')\n",
    "                    df1_sig = df1.loc[df1['Adjusted P-value'] <= 0.05]\n",
    "                    df2_sig = df2.loc[df2['Adjusted P-value'] <= 0.05]\n",
    "                    if len(df1_sig) != 0:\n",
    "                        df1_sig.to_csv(f\"tads_enrichr_results/{case}_{sample1}_{sample2}_{pathway}_0_12.tsv\", sep=\"\\t\", index=False)\n",
    "                    if len(df2_sig) != 0:\n",
    "                        df2_sig.to_csv(f\"tads_enrichr_results/{case}_{sample1}_{sample2}_{pathway}_0_60.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "                fig, ax = plt.subplots(3, 1, figsize=(10, 20))\n",
    "                plot_count = 0\n",
    "                for i, (df, pathway) in enumerate(zip(comparison_dfs, pathways)):\n",
    "                    if len(df) != 0:\n",
    "                        plot_count += 1\n",
    "                        b = df.plot.barh(x='Term', ax=ax[i], color=['#A63446', '#9DBBAE'])\n",
    "                        b.axvline(x=-np.log10(0.05), color='black', linestyle='--', alpha=0.6, linewidth=3)\n",
    "                        b.set_xlabel(f'-log$_{{10}}$(Adjusted P-value)', fontsize=20)\n",
    "                        b.set_ylabel(f'{pathway} Term', fontsize=20)\n",
    "                if plot_count != 0:\n",
    "                    fig.suptitle(f\"{case}_{sample1}_{sample2}\", fontsize=30)\n",
    "                    fig.set_tight_layout(True)\n",
    "                    fig.savefig(f\"tads_enrichr_results/{case}_{sample1}_{sample2}_pathways.svg\")\n",
    "                    fig.savefig(f\"tads_enrichr_results/{case}_{sample1}_{sample2}_pathways.png\", dpi=300, facecolor=\"white\", edgecolor='none')\n",
    "\n",
    "                fig.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
